Aime Team

AIME: TOWARDS FULLY-AUTONOMOUS MULTI-AGENT FRAMEWORK

Yexuan Shi\*, Mingyu Wang, Yunxiang Cao, Hongjie Lai, Junjian Lan,
Xin Han, Yu Wang, Jie Geng, Zhenan Li, Zihao Xia, Xiang Chen,
Chen Li, Jian Xu, Wenbo Duan, Yuanshuo Zhu

ByteDance

ABSTRACT
Multi-Agent Systems (MAS) powered by Large Language Models (LLMs) are emerging as a powerful paradigm for solving complex, multifaceted problems. However, the potential of these systems is often constrained by the prevalent plan-and-execute framework, which suffers from critical limitations: rigid plan execution, static agent capabilities, and inefficient communication. These weaknesses hinder their adaptability and robustness in dynamic environments. This paper introduces Aime, a novel multi-agent framework designed to overcome these challenges through dynamic, reactive planning and execution. Aime replaces the conventional static workflow with a fluid and adaptive architecture. Its core innovations include: (1) a Dynamic Planner that continuously refines the overall strategy based on real-time execution feedback; (2) an Actor Factory that implements Dynamic Actor instantiation, assembling specialized agents on-demand with tailored tools and knowledge; and (3) a centralized Progress Management Module that serves as a single source of truth for coherent, system-wide state awareness. We empirically evaluated Aime on a diverse suite of benchmarks spanning general reasoning (GAIA), software engineering (SWE-bench Verified), and live web navigation (WebVoyager). The results demonstrate that Aime consistently outperforms even highly specialized state-of-the-art agents in their respective domains. Its superior adaptability and task success rate establish Aime as a more resilient and effective foundation for multi-agent collaboration.

1 INTRODUCTION
The recent emergence of Large Language Models (LLMs) represents a significant milestone in artificial intelligence [Chang et al., 2024]. Demonstrating profound capabilities in natural language understanding, reasoning, and generation, LLMs now serve as the foundational technology for a new class of intelligent systems. This trend has spurred the development of LLM Agents; autonomous entities that leverage an LLM as their central cognitive engine. By augmenting LLMs with external tools, such as code interpreters or information retrieval systems, these agents can interact to execute complex, multi-step tasks, acting as versatile and autonomous problem-solvers [Wang et al., 2024b, Qin et al., 2024, Wang et al., 2024a].

Building upon the success of individual agents, the field is increasingly exploring Multi-Agent Systems (MAS), where teams of LLM Agents collaborate to solve complex problems that exceed the capabilities of any single agent. This paradigm is valued for its ability to decompose large-scale problems and leverage specialized agents in a synergistic manner [Shen et al., 2023, Hong et al., 2024, Tao et al., 2024]. Among the various architectures, the plan-and-execute framework has become a dominant approach [Huang et al., 2024]. In this structure, a dedicated planner agent de-constructs a user's request into a static sequence of subtasks. These subtasks are then assigned to a team of executor agents, each possessing a predefined role and toolset.

Despite its widespread adoption, the plan-and-execute model exhibits critical limitations, particularly in dynamic or unpredictable environments. The rigid separation of planning and execution

\*Corresponding Author, E-mail: shiyexuan@bytedance.com

<watermark>arXiv:2507.11988v2 [cs.AI] 17 Jul 2025<watermark>
<page_number>1<page_number>

Aime Team

introduces significant operational friction. Our work identifies three fundamental challenges that curtail the effectiveness of these systems: (1) *Rigid Plan Execution*. Plans are generated once and are typically brittle. The planner remains idle during execution, rendering the system unable to adapt to real-time feedback or unexpected outcomes produced by the executors. (2) *Static Agent Capabilities*. Agents are confined to predefined roles and toolkits. This rigidity limits the system’s ability to handle unforeseen tasks that demand novel skills, thereby compromising its extensibility. (3) *Inefficient Communication*. Task handoffs between agents often result in context loss, Without a centralized state management system, agents operate with an incomplete view of the overall progress, leading to redundant work and coordination failures.

To address these limitations, this paper introduce Aime, a novel multi-agent framework designed for dynamic, reactive planning and execution. Instead of a static, top-down workflow, Aime operates on a principle of continuous adaptation. It replaces the fixed planner-executor dichotomy with a more fluid architecture comprising four core components: a *Dynamic Planner* that continuously refines strategy based on live feedback; an *Actor Factory* that instantiates specialized actors on-demand to meet specific task requirements; autonomous *Dynamic Actors* that execute tasks; and a centralized *Progress Management Module* that serves as a single source of truth for system-wide state awareness.

The primary contributions of this work are as follows:
*   We propose Aime, a novel MAS framework that replaces the rigid plan-and-execute paradigm with a fluid, adaptive system. Aime enables dynamic plan adjustments, on-demand role allocation, and streamlined coordination to effectively manage complex, evolving tasks.
*   We introduce *Dynamic Actor Instantiation*, a mechanism implemented via an Actor Factory. This component assembles specialized actors on-demand, equipping them with tailored personas, tools, and knowledge to address the limitations of static agent roles.
*   We design a centralized *Progress Management Module* that maintains a unified, real-time view of task progress. This module mitigates information loss and coordination failures by providing coherent state awareness across the entire system.
*   We conduct comprehensive experiments on challenging benchmarks for general reasoning, software engineering, and web navigation (GAIA, SWE-bench, WebVoyager). Our results show that it significantly outperforms specialized state-of-the-art frameworks in both task success rate and adaptability.

The remainder of this paper is organized as follows. Section [2] provides a detailed background on LLM Agents and Multi-Agent Systems. Section [3] presents a high-level overview of the Aime framework. Section [4] details the design of its core components. Experimental setup and results are presented in Section [5]. We then discuss the related work in Section [6] and finally, conclude the paper in Section [7].

2 BACKGROUND

This section reviews the core concepts of Large Language Model Agents (LLM Agents) and Multi-Agent Systems (MAS). We then discuss current challenges and present our research motivation.

**LLM Agent.** The emergence of Large Language Models (LLMs) has enabled a new class of autonomous systems known as LLM Agents. An LLM Agent utilizes an LLM not merely as a text generator, but as its central cognitive core for reasoning, planning, and decision-making ([Yao et al. 2023]). To transcend the inherent limitations of their static, pre-trained knowledge, these agents are augmented with external tools. This augmentation allows them to interact dynamically with their environment, granting them capabilities such as executing code, retrieving real-time information from the web, and controlling external devices ([Shi et al. 2025]). Formally, an LLM Agent, A, can be defined as a tuple:

A = {LLM, T, P, M}

<page_number>2<page_number>

Aime Team

where LLM is the cognitive engine; $T = \{\tau_1, \dots, \tau_n\}$ is a set of external tools, each with well-defined functionalities; $P$ represents the prompts that structure the LLM's reasoning process and tool-use strategies; and $M$ is a memory module for storing historical interactions, states, and con-textual information [Zhang et al., 2024].

The operational paradigm of an LLM Agent is typically an iterative cycle of reasoning, acting, and observing. The agent assesses a given goal, formulates a plan, executes an action (often by invoking a tool), and then incorporates the resulting feedback to inform its next step. This loop continues until the task is accomplished, enabling LLM Agents to deconstruct and solve complex, multi-step problems.

**Multi-Agent System.** Building upon the capabilities of individual LLM Agents, Multi-Agent Systems (MAS) represent the next frontier in collaborative AI. A MAS is composed of multiple autonomous agents operating within a shared environment, orchestrated to tackle objectives that are too complex or large in scope for a single agent to handle effectively [Guo et al., 2024]. Through structured interaction and role specialization, these agents can achieve emergent intelligence and synergy. A MAS can be formally described as:

$MAS = S(A_1, A_2, \dots, A_m)$

where each $A_i$ is an LLM Agent as previously defined, and $S$ denotes the collaboration framework that governs their interactions. This framework defines agent roles, communication protocols, and potential hierarchies.

A defining characteristic of LLM-based MAS is the use of natural language as the primary medium for inter-agent communication. This offers unprecedented flexibility compared to traditional, rigidly coded protocols. However, it also introduces significant challenges in maintaining semantic consis-tency, ensuring goal alignment, and managing complex conversational flows. The design of an effective collaboration structure $S$ is therefore critical to system performance and remains an active area of research, which leads to the challenges we address in this work.

**Motivation.** In current MAS research and applications, a widely adopted framework is the plan-and-execute framework [Huang et al., 2024]. This framework assigns specialized roles to agents, typically as planners or executors. The workflow generally unfolds in three distinct stages: (1) *Global Planning*, where a planner agent analyzes a request and decomposes it into structured subtasks; (2) *Task Assignment*, where subtasks are allocated to executor agents based on their predefined capabilities; and (3) *Execution and Feedback*, where executors complete their assigned tasks and report the outcomes.

While this paradigm offers a structured approach to multi-agent collaboration, it struggles with complex, dynamic tasks. The strict separation of planning and execution often leads to suboptimal performance, particularly in environments where task requirements can change mid-execution. Our work is motivated by three critical challenges inherent in this model:

*   **Rigid Plan Execution.** Conventional plans are often static. Once formulated, the plan-ner must typically wait for all executors to report completion before aggregating results. However, the autonomy of individual executors means their actions may deviate from the prescribed plan, leading to incomplete or redundant work. This deviation provides the planner with unreliable feedback, ultimately degrading overall system performance [Cemri et al., 2025].
*   **Static Agent Capabilities.** The plan-and-execute model presupposes that the predefined capabilities of agents are sufficient for all anticipated tasks. This assumption is often violated in practice. For instance, inaccurate or incomplete descriptions of an agent's skills can lead the planner to make suboptimal task assignments [Shen et al., 2023]. Moreover, the system cannot adapt to unforeseen tasks that demand new tools or capabilities, thus limiting its extensibility and performance on novel problems.
*   **Inefficient Communication.** The handoff of information between agents is frequently a bot-tleneck. Critical context can be lost or distorted during task delegation, hindering seamless

<page_number>3<page_number>

Aime Team
___

execution (Yan, 2025). This issue is exacerbated by the absence of a shared state management system. Agents often operate with an incomplete view of the overall progress, as status updates are typically aggregated only upon task completion. This lack of real-time shared awareness can lead to redundant efforts and critical delays.

These challenges collectively limit the effectiveness and adaptability of existing multi-agent systems (Cemri et al., 2025). Overcoming these limitations requires a more advanced framework that enables flexible execution, dynamic agent roles, and reliable, context-aware communication.

3 AIME OVERVIEW

Aime is a novel multi-agent system that transforms the traditional static plan-and-execute paradigm into dynamic, reactive planning and execution. It operates on the principle of dynamic adaptation, where both task allocation and agent capabilities evolve based on real-time execution feedback and progress updates.

3.1 FRAMEWORK

The Aime framework consists of four core components that work in concert to enable dynamic multi-agent collaboration.

<p align="center">
  <img src="path/to/figure1.png" alt="Figure 1: The workflow of Aime framework.">
  <br>
  Figure 1: The workflow of Aime framework.
</p>

*Interpretation of Figure 1: The workflow of Aime framework*

The Aime framework outlines a multi-agent system designed for dynamic task execution. It involves the following key components and their interactions:

*   **User Request:** Initiates the process, e.g., "Make a trip plan". This request is sent to the Dynamic Planner.

*   **Dynamic Planner:** Acts as the central orchestrator.
    *   **Task Decomposition (1):** Breaks down the initial request into smaller, manageable tasks.
    *   **Evaluation and Iteration (6):** Continuously monitors and refines the plan based on feedback.
    *   **Inputs:** User Request, ReAct Execution (4) from Dynamic Actor.
    *   **Outputs:** Sends (Sub) Task Dispatch (2) to Actor Factory. Sends information for Progress Update (5) to Progress Management. Generates the Final Report.

*   **Actor Factory:** Responsible for instantiating specialized actors.
    *   **Inputs:** Receives (Sub) Task Dispatch (2) from Dynamic Planner.
    *   **Actor Instantiation (3):** Based on the sub-task, it configures a Dynamic Actor by providing: Persona, (Sub) Task, Knowledge, and Toolset.
    *   **Outputs:** Sends the instantiated Dynamic Actor components to the Dynamic Actor.

*   **Dynamic Actor:** An autonomous agent that executes specific subtasks.
    *   **Inputs:** Receives Persona, (Sub) Task, Knowledge, and Toolset from Actor Factory.
    *   **ReAct Execution (4):** Employs a reasoning loop (reasoning → observation → action) to perform its task.
    *   **Outputs:** Sends ReAct Execution (4) feedback to the Dynamic Planner.

*   **Progress Management:** Tracks the status of all tasks.
    *   **Inputs:** Receives Progress Update (5) from Dynamic Planner.
    *   **Status Display:** Organizes tasks into "DONE" and "TODO" categories.
        *   **DONE:**
            <table>
              <thead>
                <tr>
                  <th></th>
                  <th></th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td>&#9745;</td>
                  <td>1. Research top attraction</td>
                </tr>
                <tr>
                  <td>&#9745;</td>
                  <td>2. Investigate transportation options</td>
                </tr>
              </tbody>
            </table>
        *   **TODO:**
            <table>
              <thead>
                <tr>
                  <th></th>
                  <th></th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td>&#9744;</td>
                  <td>1. Research hotel accommodations</td>
                </tr>
                <tr>
                  <td>&#9744;</td>
                  <td>2. Calculate total estimated budget</td>
                </tr>
                <tr>
                  <td>&#9744;</td>
                  <td>3. Create final itinerary document</td>
                </tr>
              </tbody>
            </table>

*   **Final Report:** The ultimate output of the workflow, generated by the Dynamic Planner after task completion.

**Dynamic Planner.** The *Dynamic Planner* serves as the central orchestrator for task management. It decomposes high-level objectives into a hierarchical structure of executable subtasks and maintains a global task list that tracks the status of each subtask. It continuously monitors execution progress and dynamically adapts the plan based on feedback from *Dynamic Actors* and status updates from the *Progress Management Module*.

**Actor Factory.** The *Actor Factory* is responsible for instantiating specialized actors tailored to specific subtask requirements. Upon receiving a subtask, the factory analyzes its specifications to determine the optimal configuration for an actor. This process involves selecting an appropriate persona, a relevant knowledge base, and a necessary set of tools. The factory then assembles the actor with customized prompts and system configurations, ensuring each actor is purpose-built for its assigned task.

**Dynamic Actor.** A *Dynamic Actor* is an autonomous agent that executes specific subtasks assigned by the *Dynamic Planner*. Each actor employs the ReAct framework (Yao et al., 2023).

<page_number>4<page_number>

Aime Team

operating through iterative cycles of "Reasoning" and "Action". Within each cycle, the actor selects the most suitable tool from its pre-configured toolkit, performs an action, and then evaluates the outcome based on the resulting observation. This loop continues until the subtask’s completion criteria are met.

**Progress Management Module**. The *Progress Management Module* functions as the shared memory and central state for system-wide coordination. It maintains a structured representation of the entire task hierarchy and the real-time status of all subtasks. This centralized record ensures a consistent understanding of progress among the **Dynamic Planner** and all actors. Crucially, by embedding explicit completion criteria within each task entry, the module provides clear and objective standards for validating task completion.

3.2 WORKFLOW

The Aime framework operates through the iterative workflow that orchestrates the dynamic collaboration among its components. As illustrated in Figure[1] the process begins with a user request and proceeds through a cycle of planning, actor instantiation, execution, and state updates, detailed as follows:

**Step 1: Task Decomposition**. The workflow commences when the *Dynamic Planner* receives a task from the user. The planner decomposes this request into a structured plan of subtasks and initializes the corresponding task list in the *Progress Management Module*.
**Step 2: (Sub)Task Dispatch**. The *Dynamic Planner* then identifies the next executable subtask from the plan and dispatches its specification to the *Actor Factory*.
**Step 3: Actor Instantiation**. Upon receiving the subtask specification, the *Actor Factory* instantiates a specialized *Dynamic Actor*. This actor is purpose-built for the subtask, equipped with the precise persona, knowledge, and tools required for effective execution.
**Step 4: ReAct Execution**. The newly instantiated actor executes its assigned subtask by following the ReAct paradigm. It operates in a loop of reasoning and action, invoking tools from its toolkit to make incremental progress toward the subtask’s goal.
**Step 5: Progress Update**. During execution, the actor continuously reports status updates to the *Progress Management Module*. This ensures that the global task state remains synchronized and accessible to all components, particularly the *Dynamic Planner*.
**Step 6: Evaluation and Iteration**. Once a subtask is completed, the actor reports the final outcome to the *Dynamic Planner*. The planner evaluates this outcome, updates the global plan, and returns to Step 2 to dispatch the next available subtask. This cycle repeats until the top-level user request is successfully fulfilled.

This integrated workflow directly addresses several key challenges in multi-agent collaboration. The dynamic planning and dispatch loop (Steps 2 & 6) ensures context-aware task allocation, overcoming the rigidity of static, predefined plans. The centralized *Progress Management Module* (Step 1 & 5) provides a single source of truth for task status, ensuring efficient information sharing and reduced communication overhead. Finally, on-the-fly actor instantiation (Step 3) allows for flexible role definition, creating actors precisely tailored to the task at hand, unlike systems with fixed actor roles.

4 METHODOLOGY

This section details the core components of the Aime framework: the *Dynamic Planner* (Section[4.1]), the *Actor Factory* (Section[4.2]), and the *Dynamic Actor* (Section[4.3]). We then explain how these components interact via the *Progress Management Module* (Section[4.4]), which serves as the central coordination hub.

4.1 DYNAMIC PLANNER

The *Dynamic Planner* is designed to address the execution rigidity inherent in traditional plan-and-execute frameworks. In such frameworks, the planner typically remains idle until all subtasks are

<page_number>5<page_number>

Aime Team

complete, resulting in a bottleneck for adaptation. In contrast, our *Dynamic Planner* integrates a high-level strategic overview with adaptive, incremental execution. This dual focus allows the sys- tem to maintain a clear path toward the final goal while remaining responsive to execution dynamics.

At its core, the planner manages two operational levels: maintaining the global task structure and determining the immediate next action. We formalize this dual responsibility as a single, iterative reasoning step. Given an overall goal *G*, at each step *t*, the planner, denoted as agent *A*<sub>*planner*</sub>, assesses the current task list, *L*<sub>*t*</sub>, and the history of past outcomes, *H*<sub>*t*</sub> = {*o*<sub>*1*</sub>, . . . , *o*<sub>*t*</sub>}. Its operation is defined by the function:

(*L*<sub>*t*+1*</sub>, *g*<sub>*t*+1*</sub>) = LLM<sub>*planner*</sub>(*P*<sub>*planner*</sub>, *G*, *L*<sub>*t*</sub>, *H*<sub>*t*</sub>) (1)

The planner produces two outputs in each iteration:

* *L*<sub>*t*+1*</sub> is the updated global task list. This represents the planner’s *strategic* or “big-step” output, reflecting a revised understanding of the task hierarchy based on new information. If no major strategic change is required, *L*<sub>*t*+1*</sub> may simply be a copy of *L*<sub>*t*</sub> with updated task statuses.

* *g*<sub>*t*+1*</sub> is the specific, executable action for the system to perform next. This is the *tactical* or “small-step” output, such as dispatching a subtask to the *Actor Factory*.

This formulation enables remarkable adaptability. For instance, if a subtask fails, the planner can make both strategic and tactical adjustments in a single iteration. Its strategic reasoning might modify the global plan *L*<sub>*t*+1*</sub> to include a new contingency subtask. Concurrently, its tactical decision *g*<sub>*t*+1*</sub> would be to dispatch this new subtask for immediate execution. This seamless integration of planning and re-planning is a key advantage of our approach.

The planner’s interaction with the system state is strictly mediated through the structured task list *L* maintained by the *Progress Management Module*. This disciplined approach ensures state con- sistency across the system. By maintaining a dynamic equilibrium between global planning and immediate action, the *Dynamic Planner* serves as the cornerstone of Aime’s resilience and effec- tiveness in complex, evolving environments.

4.2 ACTOR FACTORY

To overcome the limitations of predefined agent roles, Aime introduces the *Actor Factory*, a compo- nent that we term *Dynamic Actor Instantiation*. Instead of selecting from a fixed pool of general-purpose agents, the factory assembles specialized actors on-demand, tailored to the precise requirements of a given subtask *g*<sub>*t*</sub>.

Upon receiving subtask *g*<sub>*t*</sub> from the *Dynamic Planner*, the factory analyzes its specifications to determine the necessary capabilities. It then constructs a new actor, *A*<sub>*t*</sub>, by selecting and composing components from curated pools. This generation process is defined as:

*A*<sub>*t*</sub> = *F*<sub>*factory*</sub>(*g*<sub>*t*</sub>) where *A*<sub>*t*</sub> = {LLM<sub>*t*</sub>, *T*<sub>*t*</sub>, *P*<sub>*t*</sub>, *M*<sub>*t*</sub>} (2)

The factory’s primary functions are to select a dedicated toolkit *T*<sub>*t*</sub> and construct a customized system prompt *P*<sub>*t*</sub>.

**Toolkit Selection.** A significant challenge in complex MAS is managing a large and diverse set of tools. Presenting all available tools to an agent’s LLM can lead to inefficient selection or errors. To mitigate this, Aime organizes tools into pre-packaged bundles, each catering to a specific functional category (e.g., ‘WebSearch’ bundle, ‘FileSystem’ bundle). The factory selects appropriate bundles *T*<sub>*t*</sub>, rather than picking from a flat list of individual tools. This bundle-based approach ensures functional completeness and reduces the risk of critical tool omissions.

**Prompt Generation.** The system prompt *P*<sub>*t*</sub> is dynamically assembled from several modular com- ponents to create a precise operational context for the actor:
<page_number>6<page_number>

Aime Team

$P_t = \text{Compose}(\rho_t, \text{desc}(T_t), \kappa_t, \epsilon, \Gamma)$ (3)

where the components are:

*   **Persona** ($\rho_t$). Defines the actor’s professional role and expertise (e.g., “An expert travel planner specializing in creating unique and memorable journeys.”). The persona is generated to align with the subtask $g_t$, effectively creating a dedicated expert.
*   **Tool Descriptions** ($\text{desc}(T_t)$). Provides a concise, textual description of the selected toolkit $T_t$. Supplying a minimal yet sufficient set of tools narrows the LLM’s decision space, improving focus and performance.
*   **Knowledge** ($\kappa_t$). Consists of highly relevant information dynamically retrieved from a knowledge base to support the subtask. For a trip-planning task, this could include tips on identifying local attractions.
*   **Environment** ($\epsilon$). Provides global context, such as operating system details or system-wide constraints (e.g., current time, access permissions), ensuring the actor’s actions are environmentally aware.
*   **Format** ($\Gamma$). Specifies the required output structure (e.g., a JSON schema), ensuring that the actor’s responses can be reliably parsed for automated processing and state updates.

**Summary.** This on-the-fly instantiation mechanism offers two distinct advantages over systems with static agent roles. First, it equips actors with the exact capabilities required for the task, eliminating both capability gaps and the cognitive load of irrelevant tools. Second, it enhances system extensibility; new capabilities can be introduced by simply adding new tool bundles or knowledge modules, without the costly process of redesigning and re-validating a large set of static agent archetypes.

4.3 DYNAMIC ACTOR

Once instantiated by the *Actor Factory*, a *Dynamic Actor* functions as an autonomous agent dedicated to executing its assigned subtask, $g_t$. Its behavior is governed by the ReAct paradigm ([Yao et al., 2023]), which integrates reasoning and action into an iterative execution cycle.

The actor, $A_t$, executes its subtask by repeatedly invoking its core LLM. At each step $k$ of its internal loop, the actor analyzes its objective and local history to generate a new thought ($\text{thought}_{k+1}$) and a subsequent action ($\text{action}_{k+1}$). This process is formalized as:

$(\text{thought}_{k+1}, \text{action}_{k+1}) = \text{LLM}_t(P_t, (g_t, H_k))$ (4)

where $H_k$ is the sequence of previous (action, observation) pairs stored in the actor’s local memory $M_t$. This cycle unfolds through three distinct phases:

*   **Reasoning.** The actor reflects on the subtask goal, its past actions, and the resulting observations to formulate a plan for the next immediate step.
*   **Action.** Based on its reasoning, the actor selects and executes an action, typically a call to a tool from its specialized toolkit $T_t$.
*   **Observation.** The actor receives the output from the executed tool. This new observation is appended to its history $H_k$ and serves as critical context for the next reasoning phase.

A key feature of the *Dynamic Actor* is its ability to communicate progress proactively. To facilitate this, the actor’s toolkit $T_t$ is augmented with a special system-provided tool: `Update_Progress(status, message)`. Crucially, the decision to invoke this tool is not hard-coded; rather, the actor’s LLM autonomously determines the appropriate moments for reporting, such as after completing a significant milestone or encountering an obstacle. This mechanism provides the *Dynamic Planner* with a near real-time view of ongoing activities without interrupting the actor’s primary workflow.

<page_number>7<page_number>

Aime Team

The execution loop terminates when the subtask's completion criteria are met. At this point, the actor generates a final structured report $o_t$ for the *Dynamic Planner*. This report includes a conclusive summary of the outcome, a final status update, and any relevant artifacts (e.g., file paths, data outputs) required by subsequent tasks.

4.4 PROGRESS MANAGEMENT MODULE

A central challenge in multi-agent systems is maintaining a coherent and globally consistent understanding of task progress. The *Progress Management Module* addresses this by serving as the framework's centralized state manager, establishing a single source of truth for the entire task hierarchy. This ensures that the *Dynamic Planner* and all *Dynamic Actors* operate on a shared, unified view of the system's state.

4.4.1 CORE DATA STRUCTURE: THE PROGRESS LIST

The cornerstone of this module is a globally accessible, hierarchical data structure we call the *progress list*, denoted by $\mathcal{L}$. It represents the complete task decomposition from high-level objectives to granular subtasks. A typical implementation uses a human-readable and machine-parsable format like a Markdown task list:

```
- Objective 1: Perform Initial Research
  - [x] Sub-objective 1.1: Research top attractions
  - [x] Sub-objective 1.2: Investigate transportation options
- Objective 2: Finalize Itinerary and Budget
  - [ ] Sub-objective 2.1: Research hotel accommodations
  - [ ] Sub-objective 2.2: Calculate total estimated budget
  - [ ] Sub-objective 2.3: Create final itinerary document
```

The key characteristics of the progress list are:

*   **Real-time Status Tracking.** Each item is marked with its current status (e.g., completed '[x]', pending '[ ]'), providing an at-a-glance view of system-wide progress.
*   **Embedded Context and Dependencies.** The hierarchical structure implicitly encodes dependencies between tasks. Furthermore, each item can embed or link to explicit completion criteria, providing objective standards for validation.

4.4.2 COORDINATION VIA PROGRESS UPDATES

Coordination between the planner and actors is achieved through two communication protocols targeting the progress list: real-time synchronization during execution and structured conclusion upon task completion.

**Real-time Synchronization.** As detailed in Section <4.3> each *Dynamic Actor* can autonomously report incremental progress by invoking the `Update_Progress` tool. This action pushes updates to the progress list, allowing the actor to signal key milestones (e.g., "shortlisted three potential hotels in Tokyo") or flag issues (e.g., "direct flights on the desired date are fully booked") before the entire subtask is finished. This mechanism provides the *Dynamic Planner* with high-fidelity, near real-time visibility into ongoing activities, enabling more proactive and informed decision-making.

**Structured Task Conclusion.** When an actor *Aᵢ* completes its assigned subtask, it communicates the final outcome to the *Dynamic Planner* using a standardized conclusion report, *oᵢ*. This message triggers a formal update to the global state, which the planner uses to modify the progress list.

The final report *oᵢ* is a structured payload composed of three essential parts:

*   **Status Update.** An explicit update for the assigned items in the progress list, marking them as completed or failed.
*   **Conclusion Summary.** A narrative summary of the task's execution. This includes the final outcome, obstacles encountered, and key insights, providing rich context beyond a simple success/fail flag.

<page_number>8<page_number>

Aime Team

*   **Reference Pointers.** A structured collection of pointers to critical artifacts produced during the task (e.g., files, database record IDs, URLs), ensuring that outputs are traceable and accessible for subsequent tasks.

By combining a shared data structure with dual communication protocols—one for real-time updates and one for final conclusions—the *Progress Management Module* ensures that context is explicitly maintained, accurately updated, and efficiently transferred throughout the task lifecycle. This forms a robust foundation for dynamic multi-agent collaboration.

5 EXPERIMENTS

To evaluate the effectiveness of our proposed framework, we conducted a series of experiments across three diverse and challenging benchmarks.

5.1 EXPERIMENTAL SETUP

**Datasets.** We selected three benchmarks that represent a broad spectrum of complex, multi-step tasks for autonomous agents:

*   **GAIA** (Mialon et al. 2024) is a challenging benchmark for general AI assistants, comprising questions that require multi-step reasoning, tool use, and comprehension of multi-modal content. We evaluate on the public test set using the official exact string matching metric.
*   **SWE-bench Verified** (Jimenez et al. 2024) is a curated subset of SWE-bench for assessing an agent’s ability to resolve real-world software engineering problems. Success is rigorously evaluated by running unit tests to ensure the provided fix is correct and introduces no regressions.
*   **WebVoyager** (He et al. 2024) is an end-to-end benchmark for web agents that interact with live websites. Performance is measured by task success rate on 15 real-world sites.

**Baselines.** We compare Aime against state-of-the-art specialized baselines for each domain. To ensure a fair comparison, all agents, including our own, are powered by the same underlying LLM, where applicable.

*   On GAIA, we compare against leading general-purpose agent frameworks: Langfun, Trase, and OWL (Hu et al. 2025).
*   On SWE-bench Verified, our baselines are top-performing code agents: SWE-agent (Yang et al. 2024) and OpenHands (Wang et al. 2025).
*   On WebVoyager, we compare against prominent web agents: Browser use (Müller & Žunič 2024), Operator (OpenAI 2025), and Skyvern (Skyvern 2025).

5.2 EXPERIMENTAL RESULTS

Table [1] presents the main experimental results, comparing Aime against state-of-the-art specialized agents on their respective benchmarks. The data clearly demonstrates that our framework not only competes with but consistently outperforms these highly-tuned systems, establishing its strong generalization capabilities and a new state-of-the-art across these diverse domains.

**On GAIA.** Aime achieves a new state-of-the-art success rate of 77.6%, outperforming the strongest baselines like Langfun. We attribute this significant performance gain to the *Dynamic Planner*, which allows the system to flexibly adapt its strategy when initial reasoning paths fail, a crucial capability for GAIA’s complex, multi-step problems.

**On SWE-bench Verified.** Aime resolves 66.4% of the issues, surpassing top specialized agents like OpenHands. While the performance of leading agents in this domain is highly competitive, we believe our advantage stems from the *Actor Factory*. It can instantiate different types of agents on-the-fly (e.g., a “code-reader” to understand context, then a “debugger” to isolate the fault), leading to a more robust and effective problem-solving process.

<page_number>9<page_number>

Aime Team

<table>
  <caption>Table 1: Performance comparison of Aime against specialized baselines across three benchmarks. Baselines are evaluated only on their target domain, while Aime is evaluated on all three. Best scores in each column are in <b>bold</b>.</caption>
  <thead>
    <tr>
      <th>Model</th>
      <th>GAIA<br>(Success Rate %)</th>
      <th>SWE-Bench Verified<br>(Resolved %)</th>
      <th>WebVoyager<br>(Success Rate %)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td colspan="4"><i>General-Purpose Agents</i></td>
    </tr>
    <tr>
      <td>Langfun</td>
      <td>71.5</td>
      <td>-</td>
      <td>-</td>
    </tr>
    <tr>
      <td>Trase</td>
      <td>70.3</td>
      <td>-</td>
      <td>-</td>
    </tr>
    <tr>
      <td>OWL</td>
      <td>69.1</td>
      <td>-</td>
      <td>-</td>
    </tr>
    <tr>
      <td colspan="4"><i>Software Engineering Agents</i></td>
    </tr>
    <tr>
      <td>SWE-agent</td>
      <td>-</td>
      <td>62.4</td>
      <td>-</td>
    </tr>
    <tr>
      <td>OpenHands</td>
      <td>-</td>
      <td>65.8</td>
      <td>-</td>
    </tr>
    <tr>
      <td colspan="4"><i>Web Navigation Agents</i></td>
    </tr>
    <tr>
      <td>Browser use</td>
      <td>-</td>
      <td>-</td>
      <td>89.1</td>
    </tr>
    <tr>
      <td>Operator</td>
      <td>-</td>
      <td>-</td>
      <td>87</td>
    </tr>
    <tr>
      <td>Skyvern</td>
      <td>-</td>
      <td>-</td>
      <td>85.6</td>
    </tr>
    <tr>
      <td><b>Aime (Ours)</b></td>
      <td><b>77.6</b></td>
      <td><b>66.4</b></td>
      <td><b>92.3</b></td>
    </tr>
  </tbody>
</table>

On **WebVoyager**. Aime demonstrates superior robustness in live web environments, achieving an impressive 92.3% success rate. This performance exceeds strong baselines like Browser use. Unlike agents with fixed plans that may falter with unexpected website changes, Aime's tight feedback loop between the *Dynamic Actors* and the *Dynamic Planner* enables it to immediately re-plan and recover from errors, resulting in higher task completion.

6 RELATED WORK

The field of Multi-Agent Systems (MAS) has been transformed by the rise of Large Language Models (LLMs) [Brown et al., 2020; OpenAI, 2023]. Unlike traditional systems that relied on rigid, formal planning models [Ghallab et al., 2004; Rao & Georgeff, 1995], modern MAS leverage LLMs as cognitive engines, enabling unprecedented flexibility and coordination through natural language. This has spurred the development of new collaboration paradigms, which we review below.

6.1 ROLE-BASED MULTI-AGENT COLLABORATION

A dominant paradigm in modern LLM-based MAS involves assigning specialized roles to agents to decompose complex tasks, often inspired by human organizational structures. Frameworks like MetaGPT [Hong et al., 2024] and ChatDev [Qian et al., 2024] simulate a software company, where agents playing roles like "product manager" or "engineer" follow structured protocols to achieve their objectives. Similarly, **MAGIS** [Tao et al., 2024] and MarsCode Agent [Liu et al., 2024] design dedicated Standard Operating Procedures (SOPs) for software development. CodeR [Chen et al., 2024] extends this by predefining multiple SOPs and selecting one based on the task at hand. While these systems demonstrate the power of structured collaboration, their workflows and agent capabilities are largely static. This rigidity limits their ability to adapt to unforeseen circumstances or tasks that deviate from the predefined SOPs. Other frameworks like AutoGen [Wu et al., 2023] and AgentVerse [Chen et al., 2023] offer more flexible communication patterns, but the definition of agent roles and their capabilities often remains fixed.

<page_number>10<page_number>

Aime Team

6.2 AUTOMATED AGENT ARCHITECTURE DESIGN

Recognizing the limitations of static designs, a recent line of research focuses on automatically searching for optimal agent architectures. These approaches, however, typically aim to find a superior *static design* before execution begins.

*   **Workflow Optimization**: Several works aim to automate the generation of the collaboration plan itself. For example, AOP (**Li et et al. 2025**) investigates an agent-oriented planning method that leverages fast task decomposition and a reward model for efficient evaluation. Others, like AFlow (**Zhang et al. 2025b**) and Flow (**Niu et al. 2025**), automatically generate graph-based workflows, though often with the simplifying assumption of homogeneous agent capabilities. More advanced approaches such as **Agentic Supernet (Zhang et al. 2025a)** and **FlowReasoner (Gao et al. 2025)** even learn to generate these workflows from predefined agentic operators. A common limitation, however, is that these methods produce a static collaboration plan *prior to execution*, making them vulnerable to real-time events that deviate from the initial strategy.
*   **Agent Role Optimization**: Complementary research focuses on optimizing individual agent design. **AgentSquare (Shang et al. 2025)** searches for an optimal agent architecture by composing it from a set of given modules, while ADAS (**Hu et al. 2024**) automates the creation of a single agent via code generation. These methods enhance agent components but do not directly address the dynamics of multi-agent collaboration.

In contrast to these methods, Aime provides a framework for dynamic adaptation *during execution*. It combines a *Dynamic Planner*, which refines plans based on real-time outcomes, with an *Actor Factory* that implements *Dynamic Actor Instantiation* to assemble specialized agents on-demand. This approach of combining reactive planning with on-the-fly specialization offers a practical and resilient solution for adaptability, avoiding the high computational overhead of offline architecture search.

7 CONCLUSION

This paper introduced Aime, a novel framework that enables dynamic, reactive collaboration through three key innovations: a *Dynamic Planner* for adaptive strategy, an *Actor Factory* for on-demand instantiation of specialized agents, and a centralized *Progress Management Module* for coherent state awareness. It was designed specifically to address critical weaknesses in the conventional plan-and-execute framework, namely its rigid planning, static agent roles, and inefficient communication. Our experiments confirm that this approach is highly effective, with Aime significantly outperforming traditional models in adaptability, efficiency, and overall task success rate.

Our future work focus on enhancing scalability for larger agent teams and empowering agents to autonomously acquire new capabilities, reducing their reliance on pre-curated tools. By shifting the paradigm from static execution to dynamic adaptation, Aime represents a significant step toward building more resilient and intelligent autonomous systems.

REFERENCES

Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. Language models are few-shot learners. In *Advances in Neural Information Processing Systems (NeurIPS)*, volume 33, pp. 1877–1901. Curran Associates, Inc., 2020.

Mert Cemri, Melissa Z. Pan, Shuyi Yang, Lakshya A. Agrawal, Bhavya Chopra, Rishabh Tiwari, Kurt Keutzer, Aditya G. Parameswaran, Dan Klein, Kannan Ramchandran, Matei Zaharia, Joseph E. Gonzalez, and Ion Stoica. Why do multi-agent LLM systems fail? *ArXiv Preprint*, arXiv:2503.13657, 2025.

<page_number>11<page_number>

Aime Team

Yupeng Chang, Xu Wang, Jindong Wang, Yuan Wu, Linyi Yang, Kaijie Zhu, Hao Chen, Xiaoyuan Yi, Cunxiang Wang, Yidong Wang, Wei Ye, Yue Zhang, Yi Chang, Philip S. Yu, Qiang Yang, and Xing Xie. A survey on evaluation of large language models. *ACM Transactions on Intelligent Systems and Technology, 15*(3):39–1:39–45, 2024.

Dong Chen, Shaoxin Lin, Muhan Zeng, Daoguang Zan, Jian-Gang Wang, Anton Cheshkov, Jun Sun, Hao Yu, Guoliang Dong, Artem Aliev, Jie Wang, Xiao Cheng, Guangtai Liang, Yuchi Ma, Pan Bian, Tao Xie, and Qianxiang Wang. Coder: Issue resolving with multi-agent and task graphs. *ArXiv Preprint*, arXiv:2406.01304, 2024.

Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chen Qi-Min Chan, Yujia Qin, Yaxi Lu, Ruobing Xie, Zhiyuan Liu, Maosong Sun, and Jie Zhou. Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors in agents. *ArXiv Preprint*, arXiv:2308.10848, 2023.

Hongcheng Gao, Yue Liu, Yufei He, Longxu Dou, Chao Du, Zhijie Deng, Bryan Hooi, Min Lin, and Tianyu Pang. Flowreasoner: Reinforcing query-level meta-agents. *ArXiv Preprint*, arXiv:2504.15257, 2025.

Malik Ghallab, Dana S. Nau, and Paolo Traverso. *Automated planning – theory and practice*. Elsevier, 2004. ISBN 978-1-55860-856-6.

Taicheng Guo, Xiuying Chen, Yaqi Wang, Ruidi Chang, Shichao Pei, Nitesh V. Chawla, Olaf Wiest, and Xiangliang Zhang. Large language model based multi-agents: A survey of progress and challenges. In *Proceedings of the 23rd International Joint Conference on Artificial Intelligence (IJCAI)*, pp. 8048–8057. ijcai.org, 2024.

Hongliang He, Wenlin Yao, Kaixin Ma, Wenhao Yu, Yong Dai, Hongming Zhang, Zhenzhong Lan, and Dong Yu. Webvoyager: Building an end-to-end web agent with large multimodal models. In *Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (ACL)*, pp. 6864–6890. Association for Computational Linguistics, 2024.

Sirui Hong, Mingchen Zhuge, Jonathan Chen, Xiawu Zheng, Yuheng Cheng, Jinlin Wang, Ceyao Zhang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou, Chenyu Ran, Lingfeng Xiao, Chenglin Wu, and Jürgen Schmidhuber. Metagpt: Meta programming for A multi-agent collaborative framework. In *The 12th International Conference on Learning and Representations (ICLR)*. OpenReview.net, 2024.

Mengkang Hu, Yuhang Zhou, Wendong Fan, Yuzhou Nie, Bowei Xia, Tao Sun, Ziyu Ye, Zhaoxuan Jin, Yingru Li, Qiguang Chen, Zeyu Zhang, Yifeng Wang, Qianshuo Ye, Bernard Ghanem, Ping Luo, and Guohao Li. OWL: optimized workforce learning for general multi-agent assistance in real-world task automation. *ArXiv Preprint*, arXiv:2505.23885, 2025.

Shengran Hu, Cong Lu, and Jeff Clune. Automated design of agentic systems. *ArXiv Preprint*, arXiv:2408.08435, 2024.

Xu Huang, Weiwen Liu, Xiaolong Chen, Xingmei Wang, Hao Wang, Defu Lian, Yasheng Wang, Ruiming Tang, and Enhong Chen. Understanding the planning of LLM agents: A survey. *ArXiv Preprint*, arXiv:2402.02716, 2024.

Carlos E. Jimenez, John Yang, Alexander Wettig, Shunyu Yao, Kexin Pei, Ofir Press, and Karthik R. Narasimhan. Swe-bench: Can language models resolve real-world github issues? In *The 12th International Conference on Learning Representations (ICLR)*. OpenReview.net, 2024.

Ao Li, Yuexiang Xie, Songze Li, Fugee Tsung, Bolin Ding, and Yaliang Li. Agent-oriented planning in multi-agent systems. In *The 13th International Conference on Learning Representations (ICLR)*. OpenReview.net, 2025.

Yizhou Liu, Pengfei Gao, Xinchen Wang, Jie Liu, Yexuan Shi, Zhao Zhang, and Chao Peng. Marscode agent: Ai-native automated bug fixing. *ArXiv Preprint*, arXiv:2409.00899, 2024.

Grégoire Mialon, Clémentine Fourrier, Thomas Wolf, Yann LeCun, and Thomas Scialom. GAIA: a benchmark for general AI assistants. In *The 12th International Conference on Learning Representations (ICLR)*. OpenReview.net, 2024.

<page_number>12<page_number>

Aime Team

Magnus Müller and Gregor Žunič. Browser use: Enable ai to control your browser, 2024. URL [https://github.com/browser-use/browser-use](https://github.com/browser-use/browser-use)

Boye Niu, Yiliao Song, Kai Lian, Yifan Shen, Yu Yao, Kun Zhang, and Tongliang Liu. Flow: Modularized agentic workflow automation. In *The 13th International Conference on Learning Representations (ICLR)*. OpenReview.net, 2025.

OpenAI. GPT-4 technical report. *ArXiv Preprint*, arXiv:2303.08774, 2023.

OpenAI. Introducing operator, 2025. URL [https://openai.com/index/introducing-operator](https://openai.com/index/introducing-operator)

Chen Qian, Wei Liu, Hongzhang Liu, Nuo Chen, Yufan Dang, Jiahao Li, Cheng Yang, Weize Chen, Yusheng Su, Xin Cong, Juyuan Xu, Dahai Li, Zhiyuan Liu, and Maosong Sun. Chatdev: Com- municative agents for software development. In *Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (ACL)*, pp. 15174–15186. Association for Computa- tional Linguistics, 2024.

Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan, Yaxi Lu, Yankai Lin, Xin Cong, Xiangru Tang, Bill Qian, Sihan Zhao, Lauren Hong, Runchu Tian, Ruobing Xie, Jie Zhou, Mark Gerstein, and Maosong Sun. Toolllm: Facilitating large language models to mas- ter 16000+ real-world apis. In *The 12th International Conference on Learning Representations (ICLR)*. OpenReview.net, 2024.

Anand S. Rao and Michael P. Georgeff. BDI agents: From theory to practice. In *Proceedings of the 1st International Conference on Multiagent Systems*, pp. 312–319. The MIT Press, 1995.

Yu Shang, Yu Li, Keyu Zhao, Likai Ma, Jiahe Liu, Fengli Xu, and Yong Li. Agentsquare: Automatic LLM agent search in modular design space. In *The 13th International Conference on Learning Representations (ICLR)*. OpenReview.net, 2025.

Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming Lu, and Yueting Zhuang. Hug- ginggpt: Solving ai tasks with chatgpt and its friends in hugging face. In *Advances in Neural Information Processing Systems (NeurIPS)*, volume 36, pp. 38154–38180. Curran Associates, Inc., 2023.

Zhengliang Shi, Shen Gao, Lingyong Yan, Yue Feng, Xiuyi Chen, Zhumin Chen, Dawei Yin, Suzan Verberne, and Zhaochun Ren. Tool learning in the wild: Empowering language models as auto- matic tool agents. In *Proceedings of the ACM on Web Conference (WWW)*, pp. 2222–2237. ACM, 2025.

Skyvern. Automate browser-based workflows with llms and computer vision, 2025. URL [https: //www.skyvern.com/](https://www.skyvern.com/)

Wei Tao, Yucheng Zhou, Yanlin Wang, Wenqiang Zhang, Hongyu Zhang, and Yu Cheng. Magis: Llm-based multi-agent framework for github issue resolution. In *Advances in Neural Information Processing Systems (NeurIPS)*, volume 37, pp. 51963–51993. Curran Associates, Inc., 2024.

Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan, and Anima Anandkumar. Voyager: An open-ended embodied agent with large language models. *Transactions on Machine Learning Research*, 2024, 2024a.

Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, Wayne Xin Zhao, Zhewei Wei, and Jirong Wen. A survey on large language model based autonomous agents. *Frontiers of Computer Science*, 18(6):186345, 2024b.

Xingyao Wang, Boxuan Li, Yufan Song, Frank F. Xu, Xiangru Tang, Mingchen Zhuge, Jiaqi Pan, Tingya Wang, Bowen Li, Jaskirat Singh, Hoang H. Tran, Fuqiang Li, Run Ma, Mingzhang Zheng, Bill Qian, Yanjun Shao, Niklas Muennighoff, Yizhe Zhang, Binyuan Hui, Junyang Lin, and et al. Openhands: An open platform for AI software developers as generalist agents. In *The 13th International Conference on Learning Representations (ICLR)*. OpenReview.net, 2025.

<page_number>13<page_number>

Aime Team

Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang, Erkang Zhu, Beibin Li, Li Jiang, Xiaoyun Zhang, and Chi Wang. Autogen: Enabling next-gen LLM applications via multi-agent conversation framework. *arXiv Preprint, arXiv:2308.08155*, 2023.

Walden Yan. Cognition blog: Don’t build multi-agents, 2025. URL [https://cognition.ai/blog/dont-build-multi-agents](https://cognition.ai/blog/dont-build-multi-agents)

John Yang, Carlos E. Jimenez, Alexander Wettig, Kilian Lieret, Shunyu Yao, Karthik Narasimhan, and Ofir Press. Swe-agent: Agent-computer interfaces enable automated software engineering. *In Advances in Neural Information Processing Systems (NeurIPS)*, volume 37, pp. 50528–50652. Curran Associates, Inc., 2024.

Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik R. Narasimhan, and Yuan Cao. React: Synergizing reasoning and acting in language models. *In The 11th International Conference on Learning Representations (ICLR)*. OpenReview.net, 2023.

Guibin Zhang, Luyang Niu, Junfeng Fang, Kun Wang, Lei Bai, and Xiang Wang. Multi-agent architecture search via agentic supernet. *arXiv Preprint, arXiv:2502.04180*, 2025a.

Jiayi Zhang, Jinyu Xiang, Zhaoyang Yu, Fengwei Teng, Xionghui Chen, Jiaqi Chen, Mingchen Zhuge, Xin Cheng, Sirui Hong, Jinlin Wang, Bingnan Zheng, Bang Liu, Yuyu Luo, and Chenglin Wu. Aflow: Automating agentic workflow generation. *In The 13th International Conference on Learning Representations (ICLR)*. OpenReview.net, 2025b.

Zeyu Zhang, Xiaohe Bo, Chen Ma, Rui Li, Xu Chen, Quanyu Dai, Jieming Zhu, Zhenhua Dong, and Ji-Rong Wen. A survey on the memory mechanism of large language model based agents. *arXiv Preprint, arXiv:2404.13501*, 2024.

<page_number>14<page_number>