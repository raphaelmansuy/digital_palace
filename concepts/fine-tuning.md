# Fine-Tuning

Fine-tuning is the process of adapting pre-trained models to specific tasks, domains, or use cases by training them on specialized datasets. It enables customization of AI models for improved performance on particular applications while leveraging existing knowledge.

---

## üìñ Learn More

- [Model Training & Fine-Tuning](../reference/core-technologies.md#model-training--fine-tuning)
- [Fine-Tuning Research](https://finetuning.baulab.info/) ‚Äî How fine-tuning enhances existing mechanisms
- [Training Infrastructure](../reference/core-technologies.md#training-infrastructure)
- [Model Optimization](../reference/core-technologies.md#model-optimization)

---

## üõ†Ô∏è Key Frameworks & Tools

- [Unsloth](https://github.com/unslothai/unsloth) ‚Äî 2x faster, 50% less memory fine-tuning
- [Axolotl](https://github.com/OpenAccess-AI-Collective/axolotl) ‚Äî Streamlined fine-tuning toolkit
- [LLaMA Factory](https://github.com/hiyouga/LLaMA-Factory) ‚Äî Easy-to-use fine-tuning framework
- [LoRA](https://arxiv.org/abs/2106.09685) ‚Äî Low-Rank Adaptation technique
- [QLoRA](https://arxiv.org/abs/2305.14314) ‚Äî Quantized LoRA for efficient training

---

## üß† Core Concepts

- **Training Strategies:** [Model Training](../reference/core-technologies.md#model-training--fine-tuning)
- **Parameter Efficiency:** [LoRA and QLoRA techniques](../reference/core-technologies.md#training-infrastructure)
- **Domain Adaptation:** [Specialized model training](../reference/core-technologies.md#model-optimization)
- **Dataset Preparation:** [Datasets](./datasets.md)

---

## üöÄ Best Practices & Next Steps

- Start with [Model Training & Fine-Tuning](../reference/core-technologies.md#model-training--fine-tuning)
- Explore [Unsloth](https://github.com/unslothai/unsloth) for efficient fine-tuning
- See [Datasets](./datasets.md) for training data
- Follow [LLMs](./llms.md) for model architecture understanding

[Back to Concepts Hub](./README.md)
