# My Digital Palace - A Personal AI Knowledge Repository

> **Your comprehensive guide to AI technologies, tools, and implementation strategies**  
> **üÜï Updated June 2025** - OpenAI o3, Claude 4, AI Agents, Computer Use & Latest Breakthroughs

## üöÄ Quick Navigation

### üéØ **Choose Your Path**

| Your Goal | Best Starting Point | Estimated Time |
|-----------|-------------------|----------------|
| **üå± Learn AI Basics** | [Complete Beginner Guide](./learning/README.md#beginner-path) | 4-8 weeks |
| **üíº Build Business AI** | [Business AI Guide](./guides/business-ai.md) | 2-4 weeks |
| **üîß Develop AI Apps** | [Development Guide](./guides/getting-started.md) | 1-2 weeks |
| **ü§ñ Create AI Agents** | [AI Agents Guide](./guides/ai-agents.md) | 3-6 weeks |
| **üî¨ Research & Experiment** | [Research Hub](./reference/README.md) | Ongoing |
| **üöÄ Deploy to Production** | [Production Guide](./guides/deployment.md) | 2-3 weeks |

### üìö **Essential Resources**

| Resource Type | Quick Access | Purpose |
|---------------|-------------|---------|
| **üõ†Ô∏è Tools** | [Master Directory](./tools/ai-tools-master-directory.md) | Find the right tool for any task |
| **ÔøΩ Learning** | [Learning Hub](./learning/README.md) | Structured learning paths |
| **ÔøΩ Articles** | [Article Collection](./reference/articles.md) | Technical deep dives |
| **ÔøΩ Mental Models** | [Mental Models](./personal/mental-models/README.md) | Decision-making frameworks |
| **üéØ Guides** | [How-To Guides](./guides/goal-oriented-guides.md) | Step-by-step tutorials |
| **üÜï 2025 Updates** | [Latest AI Breakthroughs](./reference/2025-ai-updates.md) | Cutting-edge developments |

---

## üèõÔ∏è Repository Architecture

This repository is organized as a **digital palace** - each section serves a specific purpose in your AI learning journey:

### üìÅ **Core Directories**

```
digital_palace/
‚îú‚îÄ‚îÄ üìñ learning/           # Structured learning paths & resources
‚îú‚îÄ‚îÄ üéØ guides/            # Step-by-step implementation guides  
‚îú‚îÄ‚îÄ üõ†Ô∏è tools/             # Curated tool directories & comparisons
‚îú‚îÄ‚îÄ üìö reference/         # Quick lookups, APIs, cheat sheets
‚îú‚îÄ‚îÄ üé≠ personal/          # Learning philosophy & mental models
‚îú‚îÄ‚îÄ üì∞ articles/          # Technical articles & research
‚îú‚îÄ‚îÄ üß™ projects/          # Example implementations & templates
‚îî‚îÄ‚îÄ üí¨ community/         # Discussions, contributions, updates
```

### üéØ **Usage Philosophy**

**üå± Learn by Doing**: Start with practical projects, understand theory as you build  
**üîÑ Iterative Discovery**: Return to concepts as your understanding deepens  
**ü§ù Community Growth**: Share learnings, contribute improvements, help others  
**üìà Continuous Updates**: Stay current with the rapidly evolving AI landscape

---

## ÔøΩ What's Inside

### **üÜï Latest 2025 Breakthroughs**
- **[Revolutionary AI Models](./reference/2025-ai-updates.md#revolutionary-model-breakthroughs)** - o3, Claude 4, DeepSeek R1, and next-gen reasoning
- **[AI Coding Revolution](./reference/2025-ai-updates.md#revolutionary-ai-coding-tools)** - Cursor, v0, Windsurf, and computer-use agents
- **[Voice AI Breakthrough](./reference/2025-ai-updates.md#revolutionary-voice-ai-models)** - Real-time conversation with Moshi and Kyutai Labs
- **[Agent Communication](./reference/2025-ai-updates.md#next-generation-agent-frameworks)** - MCP, A2A protocols, and standardized AI integrations

### **üõ†Ô∏è Comprehensive Tool Coverage**
- **[100+ AI Tools](./tools/ai-tools-master-directory.md)** - Categorized by purpose and expertise level
- **[2025 Breakthrough Tools](./tools/ai-tools-master-directory.md#2025-breakthrough-tools)** - Latest innovations reshaping AI development
- **[Production-Ready Solutions](./tools/ai-tools-master-directory.md#production--research-tools)** - Enterprise-grade platforms and frameworks

### **üéØ Goal-Oriented Guides**
- **[Build Your First AI App](./guides/goal-oriented-guides.md#getting-started)** - Zero to production in hours
- **[Create AI Agents](./guides/goal-oriented-guides.md#ai-agents--automation)** - Autonomous systems that take actions
- **[RAG & Knowledge Systems](./guides/goal-oriented-guides.md#knowledge--data-integration)** - AI with your own data
- **[Production Deployment](./guides/goal-oriented-guides.md#production-deployment)** - Scale to real users

### **üìö Deep Technical Knowledge**
- **[Core AI Technologies](./reference/core-technologies.md)** - LLMs, embeddings, inference, and optimization
- **[200+ Research Articles](./reference/articles.md)** - Cutting-edge papers and techniques
- **[Learning Pathways](./learning/README.md)** - Structured education for all levels

### **üé≠ Personal Learning Philosophy**
- **[Today I Learned](./personal/til/README.md)** - Daily discoveries and insights
- **[Mental Models](./personal/mental-models/README.md)** - Frameworks for understanding AI
- **[For the Impatient](./personal/impatient-series/README.md)** - Fast-track tutorials for experienced developers

---

## üåü What Makes This Different

### ‚úÖ **Goal-Oriented Organization**
- Organized by what you want to achieve, not just technology categories
- Clear success criteria for each guide
- Multiple paths based on your background and goals

### ‚úÖ **Curated Quality Over Quantity**
- Every tool and resource is personally tested and evaluated
- Regular updates based on community feedback and latest developments
- No affiliate links - purely value-driven recommendations

### ‚úÖ **Production-Ready Focus**
- Emphasis on building real applications that solve real problems
- Deployment and scaling considerations from day one
- Monitoring and maintenance guidance for sustainable AI systems

### ‚úÖ **Community-Driven Evolution**
- Open source and collaborative development approach
- Regular updates from practitioners and researchers worldwide
- Real-world experience and lessons learned shared openly

---

## üöÄ Getting Started

### **For Complete Beginners**
1. **Start here**: [Getting Started Guide](./guides/goal-oriented-guides.md#getting-started)
2. **Learn basics**: [Beginner Learning Path](./learning/README.md#beginner-path)
3. **Pick tools**: [Beginner-Friendly Tools](./tools/ai-tools-master-directory.md#beginner-tools)
4. **Build first project**: Follow the 30-minute quickstart

### **For Developers**
1. **Choose your focus**: [Developer Path](./learning/README.md#developer-path)
2. **Pick frameworks**: [Development Frameworks](./tools/ai-tools-master-directory.md#development-frameworks)
3. **Build applications**: [Conversational AI](./guides/goal-oriented-guides.md#building-conversational-ai) or [RAG Systems](./guides/goal-oriented-guides.md#knowledge--data-integration)
4. **Scale to production**: [Deployment Guide](./guides/goal-oriented-guides.md#production-deployment)

### **For AI Professionals**
1. **Stay current**: [2025 AI Updates](./reference/2025-ai-updates.md)
2. **Explore cutting-edge**: [Latest Tools](./tools/ai-tools-master-directory.md#2025-breakthrough-tools)
3. **Advanced patterns**: [AI Agents](./guides/goal-oriented-guides.md#ai-agents--automation)
4. **Contribute back**: Share your learnings and improvements

---

## ü§ù Contributing

This is a living document that improves with community input.

### **How to Contribute**
- **üêõ Found an error?** Open an issue with details
- **üí° Have a suggestion?** Submit a pull request with improvements
- **üìö Want to add content?** Follow our contribution guidelines
- **‚≠ê Found it helpful?** Star the repository and share with others

### **Contribution Guidelines**
- Focus on practical, tested information that adds real value
- Include clear examples and code snippets where relevant
- Maintain the goal-oriented organization structure
- Update related cross-references and navigation links

---

## üìß Connect & Support

**Creator**: [Rapha√´l MANSUY](https://www.linkedin.com/in/raphaelmansuy/)

**Community Channels**: 
- üí¨ [Discussions](https://github.com/raphaelmansuy/digital-palace/discussions) - Ask questions, share ideas
- üêõ [Issues](https://github.com/raphaelmansuy/digital-palace/issues) - Report bugs, request features
- üîî [Follow for Updates](https://github.com/raphaelmansuy/digital-palace/stargazers) - Stay notified of new content

---

## üìä Repository Stats

- **üìÇ Guides**: 15+ comprehensive tutorials covering every aspect of AI development
- **üõ†Ô∏è Tools**: 100+ curated AI tools and frameworks across all categories
- **üìö Resources**: 200+ learning materials, articles, and research papers
- **‚è∞ Last Updated**: June 29, 2025 - Featuring latest AI breakthroughs and tools
- **üë• Contributors**: Growing community of AI practitioners and researchers worldwide
- **üÜï 2025 Highlights**: OpenAI o3, Cursor AI, MCP, Computer Use agents, v0 UI generation, voice AI revolution
- **‚≠ê Focus Areas**: Production-ready tools, emerging frameworks, hands-on tutorials, goal-oriented learning

### **What's New in June 2025**
- **Revolutionary AI Coding**: Cursor, v0, Windsurf, and computer-use agents changing how we develop
- **Advanced Reasoning**: o3, DeepSeek R1, and next-gen model capabilities surpassing human performance
- **Standardized Protocols**: Model Context Protocol (MCP) enabling seamless AI integrations
- **Enterprise Agents**: Production-ready multi-agent systems and autonomous workflows
- **Voice AI Revolution**: Real-time conversation AI with Moshi achieving human-like latency
- **Enhanced RAG**: Knowledge graphs, multi-modal search, and semantic understanding

---

*"The best way to predict the future is to build it with AI."*

**Start your AI journey today** ‚Üí [Choose Your Path](#-choose-your-path)

---

*üîó **Quick Links**: [Tools](./tools/README.md) | [Guides](./guides/README.md) | [Learning](./learning/README.md) | [2025 Updates](./reference/2025-ai-updates.md) | [Articles](./reference/articles.md)*

---

## üÜï 2025 AI Landscape Updates

### Latest Model Breakthroughs
- **OpenAI o3 & o4-mini**: Advanced reasoning models with enhanced problem-solving capabilities (June 2025)
- **Claude 4 (Opus 4 & Sonnet 4)**: Anthropic's latest models with improved coding and AI agent capabilities
- **DeepSeek R1**: Open-source reasoning model challenging proprietary alternatives
- **Hunyuan A13B**: Tencent's new 13B parameter instruction-following model
- **Gemma 3**: Google's enhanced multilingual model with improved reasoning
- **Llama 3.3**: Meta's latest with improved efficiency and capabilities
- **FLUX.1-Kontext**: Black Forest Labs' advanced context-aware generation model

### Revolutionary AI Coding Tools
- **[Cursor AI](https://cursor.sh/)**: AI-powered code editor with contextual understanding
- **[v0 by Vercel](https://v0.dev/)**: Generate React components from text prompts
- **[Windsurf](https://codeium.com/windsurf)**: AI-first IDE with collaborative editing
- **[Claude Engineer](https://github.com/Doriandarko/claude-engineer)**: Advanced AI coding assistant
- **[Replit Agent](https://replit.com/)**: Complete app development from natural language

### Emerging Frameworks & Protocols

- **[Model Context Protocol (MCP)](https://modelcontextprotocol.io/)**: Standardized AI application interfaces
- **A2A Protocol (Agent-to-Agent)**: Emerging standard for direct agent-to-agent communication, enabling autonomous agents to negotiate, collaborate, and coordinate tasks without human intervention
- **AG-UI (Agent Graphical User Interface)**: Next-generation interface design specifically for AI agent interactions, featuring real-time agent status visualization and multi-agent workflow management
- **[Anthropic Computer Use](https://docs.anthropic.com/en/docs/computer-use)**: AI that can control computers directly
- **[OpenAI Swarm](https://github.com/openai/swarm)**: Multi-agent orchestration framework
- **[Vercel AI SDK 4.0](https://sdk.vercel.ai/)**: Streaming AI applications with generative UI

### Next-Generation Agent Capabilities

- **Computer Vision Agents**: AI that can see and interact with visual interfaces
- **Multimodal Reasoning**: Agents that process text, images, audio, and video simultaneously
- **Autonomous Code Generation**: AI systems that can build entire applications
- **Real-time Collaboration**: AI that works alongside humans in live environments

### Revolutionary Voice AI Models

- **[Unmute](https://unmute.sh/)**: Advanced real-time speech processing and enhancement platform
- **[Kyutai Labs](https://github.com/kyutai-labs)**: Cutting-edge research in streaming speech models
- **[Moshi](https://github.com/kyutai-labs/moshi)**: Real-time full-duplex voice conversation AI
- **[Delayed Streams Modeling](https://github.com/kyutai-labs/delayed-streams-modeling)**: Revolutionary approach to streaming multimodal AI

### Game-Changing Applications

- **[GitHub Copilot Workspace](https://github.com/features/copilot)**: AI-powered development environments
- **[Replit Bounties](https://replit.com/bounties)**: AI-assisted freelance development
- **[NotebookLM](https://notebooklm.google.com/)**: AI research assistant and audio generation
- **[Perplexity Pro](https://www.perplexity.ai/)**: Enhanced AI search with real-time information

---

## üî• Latest 2025 AI Technologies (Web-Sourced Updates)

> **Last Updated**: June 29, 2025 | Sources: GitHub, Anthropic, OpenAI, Hugging Face

### üöÄ Breakthrough Models & Capabilities

#### Latest Language Models
- **[Claude 4 (Opus 4 & Sonnet 4)](https://anthropic.com/claude/opus)** - Anthropic's most powerful models for coding and AI agents (June 2025)
- **[OpenAI o3 & o4-mini](https://openai.com/index/introducing-o3-and-o4-mini/)** - Advanced reasoning with "thinking with images" capability (April 2025)
- **[Tencent Hunyuan A13B](https://huggingface.co/tencent/Hunyuan-A13B-Instruct)** - 13B parameter instruction-following model (Updated June 2025)
- **[FLUX.1-Kontext](https://huggingface.co/black-forest-labs/FLUX.1-Kontext-dev)** - Black Forest Labs' context-aware generation (June 2025)
- **[Google Magenta Realtime](https://huggingface.co/google/magenta-realtime)** - Real-time music and audio generation (June 2025)

#### Specialized AI Systems
- **[Nanonets OCR](https://huggingface.co/nanonets/Nanonets-OCR-s)** - Advanced document understanding and extraction (June 2025)
- **[Claude Code](https://anthropic.com/claude-code)** - Dedicated coding assistant with extended thinking (February 2025)
- **[OpenAI Codex](https://openai.com/index/introducing-codex/)** - Enhanced code generation capabilities (May 2025)

### ü§ñ Next-Generation Agent Frameworks

#### Production-Ready Agent Platforms
- **[Dify](https://github.com/langgenius/dify)** - Production-ready platform for agentic workflow development (22k+ stars)
- **[Anything LLM](https://github.com/Mintplex-Labs/anything-llm)** - All-in-one desktop AI with built-in agents, MCP compatibility (Updated June 2025)
- **[CrewAI](https://github.com/crewAIInc/crewAI)** - Framework for orchestrating role-playing, autonomous AI agents
- **[Google ADK Python](https://github.com/google/adk-python)** - Google's open-source toolkit for building sophisticated AI agents (Updated minutes ago)

#### Agent Communication & Protocols
- **A2A Protocol (Agent-to-Agent Communication)** - Emerging standard for direct agent-to-agent negotiation and task coordination
- **AG-UI (Agent Graphical User Interface)** - Specialized UI patterns for agent interaction including:
  - Multi-agent workflow dashboards
  - Real-time agent status monitoring
  - Natural language command interfaces
  - Agent behavior visualization and control

#### Browser & Computer Control Agents
- **[Browser Use](https://github.com/browser-use/browser-use)** - Make websites accessible for AI agents (6k+ stars, updated 6 hours ago)
- **[OpenHands](https://github.com/All-Hands-AI/OpenHands)** - Code Less, Make More with autonomous development agents
- **[Nanobrowser](https://github.com/nanobrowser/nanobrowser)** - Chrome extension for AI-powered web automation

### üõ†Ô∏è Developer Tools & Frameworks

#### AI-Powered Development
- **[Unsloth](https://github.com/unslothai/unsloth)** - 2x faster fine-tuning for Qwen3, Llama 4, DeepSeek-R1, Gemma 3 (Updated 3 hours ago)
- **[LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory)** - Unified efficient fine-tuning of 100+ LLMs & VLMs (ACL 2024)
- **[vLLM](https://github.com/vllm-project/vllm)** - High-throughput LLM serving (Updated 1 hour ago)
- **[Quantalogic](https://github.com/quantalogic/quantalogic)** - Powerful agentic framework for complex reasoning tasks

#### Model Context Protocol Ecosystem
- **[MCP Tools](https://github.com/f/mcptools)** - Swiss Army Knife for MCP Servers
- **[Active Pieces](https://github.com/activepieces/activepieces)** - AI Agents & MCPs & AI Workflow Automation with 280+ MCP servers
- **[MCP Agent](https://github.com/lastmile-ai/mcp-agent)** - Build effective agents using Model Context Protocol

### üìä Data & RAG Technologies

#### Advanced RAG Systems
- **[RAGFlow](https://github.com/infiniflow/ragflow)** - Open-source RAG engine based on deep document understanding
- **[Quivr](https://github.com/QuivrHQ/quivr)** - Opiniated RAG for integrating GenAI in your apps
- **[Essential Web v1.0](https://huggingface.co/datasets/EssentialAI/essential-web-v1.0)** - Large-scale web dataset for AI training (75.5k downloads)

#### Specialized Data Processing
- **[FireCrawl](https://github.com/mendableai/firecrawl)** - Turn entire websites into LLM-ready markdown (Updated yesterday)
- **[Institutional Books 1.0](https://huggingface.co/datasets/institutional/institutional-books-1.0)** - Academic text dataset (38.2k downloads)

### üîí Security & Safety

#### AI Safety Developments
- **[Anthropic's Responsible Scaling Policy](https://anthropic.com/rsp-updates)** - Updated safety guidelines for AI development
- **[OpenAI Safety Research](https://openai.com/safety/)** - Latest research on AI alignment and safety
- **[Preparing for Future AI Risks in Biology](https://openai.com/index/preparing-for-future-ai-capabilities-in-biology/)** - Safety considerations for biological AI (June 2025)

#### Enterprise Security
- **[Trust & Transparency at Anthropic](https://trust.anthropic.com/)** - Enterprise security and compliance
- **[OpenAI Security Updates](https://openai.com/index/scaling-coordinated-vulnerability-disclosure/)** - Scaling security with responsible disclosure (June 2025)

### üìà Industry Applications

#### Business Integration
- **[Mattel x OpenAI](https://openai.com/index/mattels-iconic-brands/)** - Bringing AI to iconic brands (June 2025)
- **[Wix AI Website Builder](https://openai.com/index/wix/)** - Creating websites in minutes with AI (May 2025)
- **[Retell AI](https://openai.com/index/retell-ai/)** - Customizable voice agent automation with GPT-4o (June 2025)

### üéØ Key Takeaways for 2025

1. **Agent Communication**: A2A protocols are becoming essential for multi-agent systems
2. **User Interfaces**: AG-UI patterns are emerging for better human-agent interaction
3. **Real-time Capabilities**: Models now support real-time processing and generation
4. **Computer Control**: AI can now directly interact with computer interfaces
5. **Production Ready**: More frameworks are offering enterprise-grade agent solutions
6. **Safety First**: Increased focus on responsible AI development and deployment

---

*Sources: GitHub Topics (22k+ LLM repositories), Anthropic Research, OpenAI Updates, Hugging Face Models*

---

## üìö Learning & Development

- [Personal Learning & Reflection](#-personal-learning--reflection)
- [Learning Resources](#-learning-resources)
- [Mental Models](#mental-models)

### ü§ñ AI Technologies & Tools

- [AI Engineering & Development](#-ai-engineering--development)
- [Core AI Technologies](#-core-ai-technologies)
- [AI Agents](#agents)
- [RAG & Knowledge Systems](#rag)

### üîß Technical Implementation

- [Model Serving](#serving-llms)
- [Fine-tuning](#fine-tuning)
- [Prompt Engineering](#prompt-engineering)
- [Development Tools](#development)

### üìä Resources & References

- [Models & Benchmarks](#models)
- [Articles & Research](#articles)
- [Computing Resources](#computing)

---

## üéØ How To Guides - From Goal to Implementation

> Navigate by what you want to achieve rather than technology categories

### üöÄ Getting Started

#### How to: Start Your AI Development Journey

**What I want to achieve**: Begin building AI applications with no prior experience

**Prerequisites**: Basic programming knowledge (Python recommended)

**Essential Tools**:

- [Ollama](https://ollama.com/) - Run models locally without complexity
- [LangChain](https://www.langchain.com/) - Framework for LLM applications
- [Jupyter Notebooks](https://jupyter.org/) - Interactive development environment

**Learning Path**:

1. Start with ‚Üí [AI Courses](07-courses/ai_courses.md)
2. Practice with ‚Üí [Today I Learned](02-til/README.md)
3. Build first app ‚Üí [LangChain documentation](https://python.langchain.com/docs/get_started/introduction)

**Success Criteria**: Successfully run a local LLM and build a simple Q&A application

---

### üí¨ Building Conversational AI

#### How to: Create a Custom Chatbot

**What I want to achieve**: Build an intelligent conversational interface for my domain

**Essential Tools**:

- [LangChain](https://www.langchain.com/) - Conversation management
- [instructor](https://jxnl.github.io/instructor/) - Structured responses
- [Ollama](https://ollama.com/) - Local model serving
- [Vercel AI SDK](https://vercel.com/blog/ai-sdk-3-generative-ui) - UI components

**Key Concepts**: [Prompt Engineering Patterns](./01-articles/prompt_engineering_patterns/README.md)

**Success Criteria**: Chatbot that maintains context and provides relevant responses

#### How to: Add Memory to AI Conversations

**What I want to achieve**: Create AI that remembers past conversations and learns from interactions

**Essential Tools**:

- [MemGPT](https://memgpt.ai/) - Long-term memory management
- [Cognee](https://github.com/topoteretes/cognee) - Memory for AI applications
- [Zep](https://github.com/getzep/zep) - Long-term memory for assistants

**Success Criteria**: AI assistant that references previous conversations naturally

---

### üîç Knowledge & Data Integration

#### How to: Build a RAG (Retrieval-Augmented Generation) System

**What I want to achieve**: Make AI answer questions using my own documents and data

**Essential Tools**:

- [LlamaIndex](https://www.llamaindex.ai/) - Data framework for LLM applications
- [RagFlow](https://github.com/infiniflow/ragflow) - RAG engine with deep document understanding
- [pgvectorscale](https://github.com/timescale/pgvectorscale/) - Vector database
- [FireCrawl](https://github.com/mendableai/firecrawl) - Website to LLM-ready markdown

**Key Concepts**: [Embeddings Guide](./01-articles/embeddings/README.md)

**Success Criteria**: AI that accurately answers questions using your documents

#### How to: Create a Knowledge Graph for AI

**What I want to achieve**: Build interconnected knowledge that AI can navigate and reason about

**Essential Tools**:

- [LightRAG](https://github.com/HKUDS/LightRAG) - Knowledge graph RAG
- [MindGraph](https://github.com/yoheinakajima/MindGraph) - AI-powered knowledge graphs

**Success Criteria**: AI that understands relationships between concepts in your domain

---

### ü§ñ AI Agents & Automation

#### How to: Build AI Agents That Take Actions

**What I want to achieve**: Create AI that can perform tasks autonomously in digital environments

**Essential Tools**:

- [Quantalogic](https://github.com/quantalogic/quantalogic) - Powerful agentic framework
- [CrewAI](https://github.com/joaomdmoura/crewAI) - Multi-agent collaboration
- [AutoGen](https://microsoft.github.io/autogen/) - Multi-agent conversation framework
- [Pydantic Agents](https://ai.pydantic.dev/agents/) - Production-grade agent framework

**Key Concepts**: [Agent Architecture Patterns](https://techcommunity.microsoft.com/blog/machinelearningblog/baseline-agentic-ai-systems-architecture/4207137)

**Success Criteria**: Agent that completes multi-step tasks with minimal supervision

#### How to: Create AI That Controls Computers

**What I want to achieve**: Build AI that can interact with software interfaces like a human

**Essential Tools**:

- [Screen Agents](https://github.com/niuzaisheng/ScreenAgent) - Visual computer control
- [SWE Agents](https://github.com/princeton-nlp/SWE-agent) - Software engineering agents
- [Open Interpreter](https://github.com/KillianLucas/open-interpreter/) - Natural language computer interface

**Success Criteria**: AI that can navigate and operate computer applications

---

### üîß Model Customization

#### How to: Fine-tune Models for Your Domain

**What I want to achieve**: Adapt pre-trained models to perform better on my specific tasks

**Essential Tools**:

- [unsloth](https://github.com/unslothai/unsloth) - 5X faster, 60% less memory fine-tuning
- [LLama-Factory](https://github.com/hiyouga/LLaMA-Factory) - Unified fine-tuning for 100+ LLMs
- [peft](https://github.com/huggingface/peft) - Parameter-efficient fine-tuning

**Key Concepts**: [Training LLMs Guide](01-articles/2024-03-12_training_an_llm.md)

**Success Criteria**: Model that significantly outperforms base model on your domain

#### How to: Generate Synthetic Training Data

**What I want to achieve**: Create high-quality training data when real data is scarce

**Essential Tools**:

- [Bonito](https://github.com/BatsResearch/bonito) - Synthetic instruction tuning datasets
- [instructor](https://jxnl.github.io/instructor/) - Structured data generation

**Success Criteria**: Generated dataset that improves model performance

---

### üöÄ Production Deployment

#### How to: Serve Models at Scale

**What I want to achieve**: Deploy AI models that can handle production traffic efficiently

**Essential Tools**:

- [vLLM](https://github.com/vllm-project/vllm) - High-throughput LLM serving
- [Ollama](https://ollama.com/) - Simple local deployment
- [SkyPilot](https://skypilot.readthedocs.io/en/latest/) - Multi-cloud deployment
- [LoraX](https://github.com/predibase/lorax) - Multi-LoRA inference server

**Success Criteria**: Model serving with sub-second response times and high availability

#### How to: Optimize Models for Performance

**What I want to achieve**: Make models faster and use less memory while maintaining quality

**Essential Tools**:

- [hqq](https://github.com/mobiusml/hqq) - Half-quadratic quantization
- [Candle](https://github.com/huggingface/candle) - Rust-based inference
- [AICI](https://github.com/microsoft/AICI) - Controlled generation

**Success Criteria**: 2-4x speedup with minimal quality loss

---

### üé® Specialized Applications

#### How to: Build AI-Powered User Interfaces

**What I want to achieve**: Create applications with AI-generated or AI-enhanced UIs

**Essential Tools**:

- [OpenUI](https://github.com/wandb/openui) - Describe UI with natural language
- [Screenshot to Code](https://github.com/abi/screenshot-to-code) - Convert designs to code
- [Vercel AI SDK](https://vercel.com/blog/ai-sdk-3-generative-ui) - Stream React components

**Success Criteria**: Working application with AI-generated interface components

#### How to: Add Voice Capabilities

**What I want to achieve**: Create AI that can understand speech and respond with natural voice

**Essential Tools**:

- [whisper](https://github.com/openai/whisper) - Speech recognition
- [MeloTTS](https://github.com/myshell-ai/MeloTTS) - High-quality text-to-speech
- [VoiceCraft](https://github.com/jasonppy/VoiceCraft) - Zero-shot speech editing

**Success Criteria**: Natural voice conversation with AI

#### How to: Process Documents with AI

**What I want to achieve**: Extract structured information from PDFs, images, and documents

**Essential Tools**:

- [zerox](https://github.com/getomni-ai/zerox) - OCR & document extraction using vision models
- [lumentis](https://github.com/hrishioa/lumentis) - Generate docs from transcripts

**Success Criteria**: Accurate data extraction from various document formats

---

### üìä Monitoring & Evaluation

#### How to: Ensure AI Output Quality

**What I want to achieve**: Implement checks and balances to maintain AI system reliability

**Essential Tools**:

- [instructor](https://jxnl.github.io/instructor/) - Structured output validation
- [BAML](https://github.com/BoundaryML/baml) - Reliable structured data from LLMs
- [Guidance](https://github.com/guidance-ai/guidance) - Controlled generation

**Success Criteria**: AI system with consistent, validated outputs

---

## üß≠ Quick Navigation Guide

> Choose your path based on your experience level and goals

### üå± **New to AI Development?**

Start here ‚Üí [How to: Start Your AI Development Journey](#how-to-start-your-ai-development-journey)

### üíº **Building Business Applications?**

- [How to: Create a Custom Chatbot](#how-to-create-a-custom-chatbot)
- [How to: Build a RAG System](#how-to-build-a-rag-retrieval-augmented-generation-system)
- [How to: Ensure AI Output Quality](#how-to-ensure-ai-output-quality)

### üî¨ **Research & Experimentation?**

- [How to: Fine-tune Models](#how-to-fine-tune-models-for-your-domain)
- [How to: Generate Synthetic Data](#how-to-generate-synthetic-training-data)
- [Core AI Technologies](#-core-ai-technologies)

### üè≠ **Production Deployment?**

- [How to: Serve Models at Scale](#how-to-serve-models-at-scale)
- [How to: Optimize Model Performance](#how-to-optimize-models-for-performance)
- [Model Serving Tools](#serving-llms)

### ü§ñ **Advanced AI Agents?**

- [How to: Build AI Agents](#how-to-build-ai-agents-that-take-actions)
- [How to: AI Computer Control](#how-to-create-ai-that-controls-computers)
- [Agent Frameworks](#agents)

## ÔøΩ Legacy Content

The complete content from the original README has been preserved and reorganized into focused guides. Here are the key redirects:

### üìö Personal Learning & Reflection
- **Today I Learned (TIL)** ‚Üí [Personal TIL Collection](./personal/til/README.md)
- **Mental Models** ‚Üí [Mental Models Guide](./personal/mental-models/README.md)  
- **"For the Impatient" Series** ‚Üí [Impatient Series](./personal/impatient-series/README.md)

### üéì Complete Learning Resources
- **Comprehensive Learning Hub** ‚Üí [Learning Resources Hub](./learning/learning-resources-hub.md)
- **Course Collections** ‚Üí [AI Courses](./reference/courses.md)
- **Books & Reading** ‚Üí [Essential Books](./reference/books.md)

### üõ†Ô∏è Technical References
- **All AI Tools** ‚Üí [AI Tools Master Directory](./tools/ai-tools-master-directory.md)
- **Framework Comparisons** ‚Üí [Framework Selection Guide](./tools/framework-comparison.md)
- **Model Information** ‚Üí [Model Comparison](./reference/models.md)

### üìÑ Article Collections
- **All Articles** ‚Üí [Article Index](./reference/articles.md)
- **Research Papers** ‚Üí [Paper Collection](./reference/research-papers.md)
- **Blog Posts** ‚Üí [Quality Blogs](./reference/blogs.md)

---

## ü§ñ AI Engineering & Development

### Core Concepts & Frameworks

- [Generative AI Business Use Cases](01-articles/2024-03-12_genai_business_use_cases.md)
- [Comprehensive Guide to Large Language Model Engineering](11-genai/README.md.md)
- [Design and Architecture Patterns for LLM Applications](./01-articles/dessign_patterns_for_llm_applications/README.md)
- [Frameworks for Building LLM Applications](./01-articles/framework_for_llm_applications/README.md)
- [Demystifying Classifiers and Embeddings](./01-articles/embeddings/README.md)
- [Bridging the Gap Between Thinking and Doing: FaR an Effective Prompting Framework inspired from Theory of Mind](./01-articles/far/README.md)
- [Beyond Prompt Engineering: Modular and Optimized LM Programs with DSPy](./01-articles/dspy/README.md)
- [Mastering the Art of Training Large Language Models from Scratch](01-articles/2024-03-12_training_an_llm.md)

### AI Application Development

#### Core Frameworks & Libraries

- [LangChain](https://www.langchain.com/) - Framework to construct LLMs application [documentation](https://python.langchain.com/docs/get_started/introduction) ü¶ú
- [LLamaIndex](https://www.llamaindex.ai/) - Turn your enterprise data into production-ready LLM applications ü¶ô
- [HuggingFace](https://huggingface.co/) - Model, Datasets, Inference Space, the GitHub of AI models ü§ó
  - [Hub](https://huggingface.co/docs/hub/index) - Your starting point to HuggingFace
  - [CLI](https://huggingface.co/docs/huggingface_hub/en/guides/cli) - Command Line Interface (CLI)
- [Quantalogic](https://github.com/quantalogic/quantalogic) - A powerful Agentic Framework
- [QLLM](https://github.com/quantalogic/qllm) - QLLM: A powerful CLI for seamless interaction with multiple Large Language Models. Simplify AI workflows, streamline development, and unlock the potential of cutting-edge language models. by [Quantalogic](https://www.quantalogi.app)

#### Specialized Tools

- [instructor](https://jxnl.github.io/instructor/) - Instructor makes it easy to reliably get structured data like JSON from Large Language Models (LLMs) like GPT-3.5, GPT-4, GPT-4-Vision, including open source models like Mistral/Mixtral from [Together](https://jxnl.github.io/instructor/hub/together/), [Anyscale](https://jxnl.github.io/instructor/hub/anyscale/), [Ollama](https://jxnl.github.io/instructor/hub/ollama/), and [llama-cpp-python](https://jxnl.github.io/instructor/hub/llama-cpp-python/).
- [instructor_ex](https://github.com/thmsmlr/instructor_ex) - (Elixir version of Instructor)
- [BAML](https://github.com/BoundaryML/baml) - BAML is a language that helps you get structured data from LLMs, with the best DX possible. Works with all languages. Check out the promptfiddle.com playground
- [ell](https://docs.ell.so/index.html#) - A language model programming framework
- [marvin](https://www.askmarvin.ai/welcome/what_is_marvin/) - Marvin is a lightweight AI toolkit for building natural language interfaces that are reliable, scalable, and easy to trust
- [PhiData](https://docs.phidata.com/introduction) - Phidata is a toolkit for building AI Assistants using function calling

#### Utility & Enhancement Tools

- [Vercel AI SDK](https://vercel.com/blog/ai-sdk-3-generative-ui) - Stream React Components from LLMs to deliver richer user experiences
- [easyllm](https://philschmid.github.io/easyllm/) - EasyLLM is an open source project that provides helpful tools and methods for working with large language models (LLMs), both open source and closed source
- [Flowneum](https://github.com/floneum/floneum) - A toolkit for controllable, private AI on consumer hardware in rust
- [Kalosm](https://floneum.com/kalosm/) - Kalosm is an open source framework for private language, audio, and image models in Rust
- [Microsoft AutoDev](https://github.com/unit-mesh/auto-dev) - üßô‚ÄçAutoDev: The AI-powered coding wizard with multilingual support
- [Cognee](https://github.com/topoteretes/cognee?tab=readme-ov-file) - Memory management for the AI Applications and AI Agents
- [MemGPT](https://memgpt.ai/) - Enable Next-Gen Large Language Model Applications
- [lumentis](https://github.com/hrishioa/lumentis) - Generate beautiful docs from your transcripts and unstructured information with a single command
- [OpenUI](https://github.com/wandb/openui) - OpenUI let's you describe UI using your imagination, then see it rendered live
- [FireCrawl](https://github.com/mendableai/firecrawl) - Turn entire websites into LLM-ready markdown
- [Sammo](https://github.com/microsoft/sammo) - A library for prompt engineering and optimization (SAMMO = Structure-aware Multi-Objective Metaprompt Optimization)
- [Awesome Python](https://github.com/vinta/awesome-python)
- [Oumi](https://github.com/oumi-ai/oumi) - Everything you need to build state-of-the-art foundation models, end-to-end

### AI-Assisted Development

- [Plandex](https://github.com/plandex-ai/plandex) - An AI coding engine for complex tasks
- [Aider](https://github.com/paul-gauthier/aider) - aider is AI pair programming in your terminal

### Command-Line AI Tools

- [llms](https://llm.datasette.io/en/stable/) - A CLI utility and Python library for interacting with Large Language Models, both via remote APIs and models that can be installed and run on your own machine. By [Simon Willison](https://simonwillison.net/)
- [Open Interpreter](https://github.com/KillianLucas/open-interpreter/) - A natural language interface for computers
- [Documentation Open Interpreter](https://docs.openinterpreter.com/getting-started/introduction) - A new way to use computers
- [whisper](https://github.com/openai/whisper) - Whisper is a general-purpose speech recognition model. It is trained on a large dataset of diverse audio and is also a multitasking model that can perform multilingual speech recognition, speech translation, and language identification
- [plock](https://github.com/jasonjmcghee/plock) - From anywhere you can type, query and stream the output of an LLM or any other script
- [Screen shot to code](https://github.com/abi/screenshot-to-code) - Drop in a screenshot and convert it to clean code (HTML/Tailwind/React/Vue)
- [Code2prompt](https://github.com/raphaelmansuy/code2prompt) - Convert a codebase to an AI prompt
- [Claude Engineer](https://github.com/Doriandarko/claude-engineer) - Claude Engineer is an interactive command-line interface (CLI) that leverages the power of Anthropic's Claude-3.5-Sonnet model to assist with software development tasks. This tool combines the capabilities of a large language model with practical file system operations and web search functionality

---


## üß† Core AI Technologies

### Large Language Models (LLMs)

#### LLMs Implementation

- [LLMs from scratch](https://github.com/rasbt/LLMs-from-scratch) - Implementing a ChatGPT-like LLM from scratch, step by step by from [Sebastian Raschka](https://github.com/rasbt)

#### Model Serving & Inference

**High-Performance Servers:**
- [vLLM](https://github.com/vllm-project/vllm) - Easy, fast, and cheap LLM serving for everyone, [documentation](https://docs.vllm.ai/en/latest/)
- [llamaC++](https://github.com/ggerganov/llama.cpp) - LLM inference in C/C++
- [Ollama](https://github.com/ollama/ollama) - Go program that encapsulate [llamac++](https://github.com/ggerganov/llama.cpp). [documentation](https://ollama.com/)
- [nm-vllm](https://github.com/neuralmagic/nm-vllm) - A high-throughput and memory-efficient inference and serving engine for LLMs (sparse compressing)

**Specialized Solutions:**
- [Candle](https://github.com/huggingface/candle?tab=readme-ov-file) - Minimalist ML framework for Rust. Run and Serve Models in Rust
- [ZML](https://github.com/zml/zml) - High performance AI inference stack. Built for production. [@ziglang](https://github.com/ziglang) / [@openxla](https://github.com/openxla) / MLIR / [@bazelbuild](https://github.com/bazelbuild)
- [LLamafile](https://github.com/Mozilla-Ocho/llamafile) - Turning a LLM model into a Multiplatform executable
- [Jan](https://github.com/janhq/jan) - Jan is an open source alternative to ChatGPT that runs 100% offline on your computer
- [MLX Omni Server](https://github.com/madroidmaq/mlx-omni-server) - MLX Omni Server is a local inference server powered by Apple's MLX framework, specifically designed for Apple Silicon (M-series) chips. It implements OpenAI-compatible API endpoints, enabling seamless integration with existing OpenAI SDK clients while leveraging the power of local ML inference
- [Mlx Server](https://www.mlxserver.com/) - This Python library is the easist way to begin building on top of Apple's machine learning library MLX
- [fastassert](https://github.com/phospho-app/fastassert) - Dockerized LLM inference server with constrained output (JSON mode), built on top of vLLM and outlines
- [luminal](https://github.com/jafioti/luminal) - Deep learning at the speed of light coded in Rust. The aim for 0.3 is to achieve SOTA performance on an M1 pro (50 tok/s), and near SOTA on single nvidia gpus (>100 tok/s)

**Cloud & Distributed:**
- [SkyPilot](https://docs.vllm.ai/en/latest/) - Run LLMs and AI on Any Cloud [documentation](https://skypilot.readthedocs.io/en/latest/)
- [LoraX](https://github.com/predibase/lorax) - Multi-LoRA inference server that scales to 1000s of fine-tuned LLMs ([Documentation](https://loraexchange.ai/))
- [LLama Cpp Python Binding](https://llama-cpp-python.readthedocs.io/en/latest/) - OpenAI compatible web server

**Resources:**
- [List of tools that serves AI locally](https://github.com/janhq/awesome-local-ai) - An awesome repository of local AI tools

#### Model Training & Fine-Tuning

**Fine-Tuning Frameworks:**
- [unsloth](https://github.com/unslothai/unsloth/tree/main#-documentation) - 5X faster 60% less memory QLoRA finetuning
- [LLama-Factory](https://github.com/hiyouga/LLaMA-Factory) - Unify Efficient Fine-tuning of 100+ LLMs
- [peft](https://github.com/huggingface/peft) - ü§ó PEFT: State-of-the-art Parameter-Efficient Fine-Tuning
- [Torchtune](https://github.com/pytorch/torchtune) - A Native-PyTorch Library for LLM Fine-tuning
- [LLMTuner](https://github.com/promptslab/LLMTuner) - Tune LLM in few lines of code
- [LMFlow](https://github.com/OptimalScale/LMFlow) - An Extensible Toolkit for Finetuning and Inference of Large Foundation Models. Large Models for All. (Include Lisa Finetuning)

**Training Infrastructure:**
- [OLMo](https://github.com/allenai/OLMo) - Modeling, training, eval, and inference code for [OLMo](https://allenai.org/olmo)
- [Lightning Thunder](https://github.com/Lightning-AI/lightning-thunder) - Source to source compiler for PyTorch. It makes PyTorch programs faster on single accelerators and distributed

**Resources:**
- [Documentation from Premai about Finetuning](https://book.premai.io/state-of-open-source-ai/fine-tuning/)
- [Efficient finetuning of Llama 3 with FSDP QDoRA](https://www.answer.ai/posts/2024-04-26-fsdp-qdora-llama3.html) - A blog article that explains how to use the stat of the art QDoRA fine tuning method on LLAMA3

#### Model Optimization

**Quantization:**
- [Aimet](https://github.com/quic/aimet) - AIMET is a library that provides advanced quantization and compression techniques for trained neural network models from Qualcomm Innovation Center
- [hqq](https://github.com/mobiusml/hqq) - Official implementation of Half-Quadratic Quantization (HQQ). **HQQ** is a fast and accurate model quantizer that skips the need for calibration data. It's super simple to implement (just a few lines of code for the optimizer). It can crunch through quantizing the Llama2-70B model in only 4 minutes! üöÄ

**Inference Control:**
- [Guidance](https://github.com/guidance-ai/guidance) - A guidance language for controlling large language models
- [AICI](https://github.com/microsoft/AICI) - AICI: Prompts as (Wasm) Programs. Controlling inference using Wasm programs
- [Transformer Head](https://github.com/center-for-humans-and-machines/transformer-heads) - Toolkit for attaching, training, saving and loading of new heads for transformer models
- [Representation Engineering](https://vgel.me/posts/representation-engineering/) - Representation Engineering Mistral-7B an Acid Trip üíä

### Embeddings & Vector Operations

**Core Concepts:**
- [What are embeddings and how do they work? A book from Vicki Boykis](https://vickiboykis.com/what_are_embeddings/)
  - [Github](https://github.com/veekaybee/what_are_embeddings)
  - [PDF](https://raw.githubusercontent.com/veekaybee/what_are_embeddings/main/embeddings.pdf)
- [Fine-tuning language models improves performance by enhancing existing mechanisms rather than creating new ones, as evidenced by consistent circuit functionality in entity tracking tasks](https://finetuning.baulab.info/)
- [Introduction to Matryoshka Embedding Models](https://huggingface.co/blog/matryoshka)
- [Binary Embeddings Cohere](https://txt.cohere.com/int8-binary-embeddings/)

**Vector Databases:**
- [pgvectorscale](https://github.com/timescale/pgvectorscale/) - A complement to pgvector for high performance, cost efficient vector search on large workloads

### Prompt Engineering

**Techniques & Patterns:**
- [Summoning the Magic of Prompts: A Deep Dive into Prompt Engineering Patterns](./01-articles/prompt_engineering_patterns/README.md)
- [A list of prompt engineering techniques](https://aman.ai/primers/ai/prompt-engineering/)
- [Mastering the art of prompt engineering](01-articles/2024-05-29_mastering-prompt-engineering_us.md)
- [Mastering the art of prompt engineering in French](01-articles/2024-05-29_mastering_prompt_engineering_fr.md)

**Advanced Frameworks:**
- [Claude Anthropic Prompts Library](https://docs.anthropic.com/claude/page/prompts) - Explore optimized prompts for a breadth of business and personal tasks
- [Navigating the Prompt Engineering Landscape: A Comprehensive Survey for NLP Practitioners](https://arxiv.org/pdf/2407.12994)

---

## LLM Applications

[What are the common use cases of LLM Applications ?](./01-articles/llm_applications_use_cases/README.md)

- [ottogrid](https://ottogrid.ai/) 


### Front End

[Bionic GPT]([https://github.com/bionic-gpt/bionic-gpt/blob/main/README.md) **BionicGPT is an on-premise replacement for ChatGPT, offering the advantages of Generative AI while maintaining strict data confidentiality**¬†BionicGPT can run on your laptop or scale into the data center.
[Lobe Chat](https://github.com/lobehub/lobe-chat) ü§Ø Lobe Chat - an open-source, modern-design AI chat framework. Supports Multi AI Providers( OpenAI / Claude 3 / Gemini / Ollama / Azure / DeepSeek), Knowledge Base (file upload / knowledge management / RAG ), Multi-Modals (Vision/TTS) and plugin system. One-click FREE deployment of your private ChatGPT/ Claude application.



### Toolbox

- [Quantalogic](https://github.com/quantalogic/quantalogic) A powerful Agentic Framework
- [QLLM](https://github.com/quantalogic/qllm)  QLLM: A powerful CLI for seamless interaction with multiple Large Language Models. Simplify AI workflows, streamline development, and unlock the potential of cutting-edge language models. by [Quantalogic](https://www.quantalogi.app)
- [BAML](https://github.com/BoundaryML/baml) BAML is a language that helps you get structured data from LLMs, with the best DX possible. Works with all languages. Check out the promptfiddle.com playground
- [ell](https://docs.ell.so/index.html#) A language model programming framework.
- [LangChain](https://www.langchain.com/) Framework to construct LLMs application [documentation](https://python.langchain.com/docs/get_started/introduction) ü¶ú
- [LLamaIndex](https://www.llamaindex.ai/)Turn your enterprise data into production-ready LLM applications ü¶ô
- [HuggingFace](https://huggingface.co/) Model, Datasets, Inference Space, the GitHub of AI models. ü§ó
	- [Hub](https://huggingface.co/docs/hub/index) Your starting point to HuggingFace
	- [cli](https://huggingface.co/docs/huggingface_hub/en/guides/cli) Command Line Interface (CLI)
- [instructor](https://jxnl.github.io/instructor/) Instructor makes it easy to reliably get structured data like JSON from Large Language Models (LLMs) like GPT-3.5, GPT-4, GPT-4-Vision, including open source models like Mistral/Mixtral from¬†[Together](https://jxnl.github.io/instructor/hub/together/),¬†[Anyscale](https://jxnl.github.io/instructor/hub/anyscale/),¬†[Ollama](https://jxnl.github.io/instructor/hub/ollama/), and¬†[llama-cpp-python](https://jxnl.github.io/instructor/hub/llama-cpp-python/).
- [instructor_ex](https://github.com/thmsmlr/instructor_ex) (Elixir version of Instructor)
- [marvin](https://www.askmarvin.ai/welcome/what_is_marvin/) Marvin is a lightweight AI toolkit for building natural language interfaces that are reliable, scalable, and easy to trust. 
- [Vercel AI SDK](https://vercel.com/blog/ai-sdk-3-generative-ui) (Stream React Components from LLMs to deliver richer user experiences)
- [easyllm](https://philschmid.github.io/easyllm/) EasyLLM is an open source project that provides helpful tools and methods for working with large language models (LLMs), both open source and closed source.

- [Flowneum](https://github.com/floneum/floneum) A toolkit for controllable, private AI on consumer hardware in rust
- [Kalosm](https://floneum.com/kalosm/) Kalosm is an open source framework for private language, audio, and image models in Rust
- [PhiData](https://docs.phidata.com/introduction) Phidata is a toolkit for building AI Assistants using function calling.
- [Microsoft AutoDev](https://github.com/unit-mesh/auto-dev) üßô‚ÄçAutoDev: The AI-powered coding wizard with multilingual support
- [Cognee](https://github.com/topoteretes/cognee?tab=readme-ov-file) Memory management for the AI Applications and AI Agents
- [MemGPT](https://memgpt.ai/) Enable Next-Gen Large Language Model Applications
- [lumentis](https://github.com/hrishioa/lumentis) Generate beautiful docs from your transcripts and unstructured information with a single command.
- [Wantdb/OpenUI](https://github.com/wandb/openui) OpenUI let's you describe UI using your imagination, then see it rendered live.
- [FireCrawl](https://github.com/mendableai/firecrawl) Turn entire websites into LLM-ready markdown
- [Sammo](https://github.com/microsoft/sammo) A library for prompt engineering and optimization (SAMMO = Structure-aware Multi-Objective Metaprompt Optimization)
- [Awesome Python](https://github.com/vinta/awesome-python) 
- [Oumi](https://github.com/oumi-ai/oumi) Everything you need to build state-of-the-art foundation models, end-to-end.


## AI Assisted Coding & Development

### Next-Generation AI Code Editors
- **[Cursor](https://cursor.sh/)** - AI-first code editor with contextual understanding and codebase analysis
- **[Windsurf](https://codeium.com/windsurf)** - Collaborative AI IDE with real-time assistance
- **[GitHub Copilot Workspace](https://github.com/features/copilot)** - AI-powered development environments
- **[Replit Agent](https://replit.com/)** - Complete application development from natural language

### AI Pair Programming Tools
- **[Plandex](https://github.com/plandex-ai/plandex)** - An AI coding engine for complex tasks
- **[Aider](https://github.com/paul-gauthier/aider)** - aider is AI pair programming in your terminal
- **[Claude Engineer](https://github.com/Doriandarko/claude-engineer)** - Advanced AI coding assistant with file system operations
- **[Continue](https://continue.dev/)** - Open-source autopilot for VS Code and JetBrains

### Code Generation & UI Building
- **[v0 by Vercel](https://v0.dev/)** - Generate React components and full applications from prompts
- **[Screenshot to Code](https://github.com/abi/screenshot-to-code)** - Drop in a screenshot and convert it to clean code
- **[OpenUI](https://github.com/wandb/openui)** - Describe UI using your imagination, then see it rendered live
- **[Code2prompt](https://github.com/raphaelmansuy/code2prompt)** - Convert a codebase to an AI prompt

### AI Code Analysis & Security
- **[CodeRabbit](https://coderabbit.ai/)** - AI-powered code reviews and suggestions
- **[Snyk DeepCode](https://snyk.io/platform/deepcode-ai/)** - AI-powered security and code quality analysis
- **[Amazon CodeWhisperer](https://aws.amazon.com/codewhisperer/)** - AI coding companion with security scanning

### Cursor AI Ecosystem
- **[Awesome Cursor Rules](https://github.com/PatrickJS/awesome-cursorrules)** - Curated collection of .cursorrules files
- **[Cursor Directory](https://cursor.directory/)** - Discover Cursor Rules & MCP Servers
- **[Cursor AI Extensions](https://marketplace.visualstudio.com/search?term=cursor&target=VSCode)** - Enhanced extensions for Cursor

## AI Haking

[How to Hack AI Apps](https://josephthacker.com/hacking/2025/02/25/how-to-hack-ai-apps.html)  How to Hack AI Agents and Applications

## RAG & Knowledge Systems - 2025 Edition

### Advanced RAG Frameworks
- **[RagFlow](https://github.com/infiniflow/ragflow)** - RAG engine with deep document understanding and visual parsing
- **[LightRAG](https://github.com/HKUDS/LightRAG)** - Knowledge graph RAG with entity relationship understanding
- **[RAG Techniques](https://github.com/NirDiamant/RAG_Techniques)** - Advanced RAG implementation patterns and techniques
- **[LlamaIndex](https://www.llamaindex.ai/)** - Production-ready data framework for LLM applications

### Next-Gen Vector & Search
- **[pgvectorscale](https://github.com/timescale/pgvectorscale/)** - High-performance vector search for large workloads
- **[byaldi](https://github.com/AnswerDotAI/byaldi)** - Late-interaction multi-modal models (ColPali) for document search
- **[Weaviate](https://weaviate.io/)** - Vector database with hybrid search capabilities
- **[Qdrant](https://qdrant.tech/)** - High-performance vector similarity search engine

### Document Processing & Extraction
- **[zerox](https://github.com/getomni-ai/zerox)** - OCR & document extraction using vision models
- **[FireCrawl](https://github.com/mendableai/firecrawl)** - Turn websites into LLM-ready markdown
- **[lumentis](https://github.com/hrishioa/lumentis)** - Generate docs from transcripts and unstructured data
- **[Unstructured](https://unstructured.io/)** - Transform documents for LLM applications

### Knowledge Graph & Reasoning
- **[MindGraph](https://github.com/yoheinakajima/MindGraph)** - AI-powered knowledge graph generation and querying
- **[Neo4j Vector Index](https://neo4j.com/docs/cypher-manual/current/indexes-for-vector-search/)** - Graph database with vector search
- **[Microsoft GraphRAG](https://github.com/microsoft/graphrag)** - Knowledge graph enhanced RAG
- **[LangChain Graph](https://python.langchain.com/docs/use_cases/graph/)** - Graph-based question answering

### Semantic Search & Embeddings
- **[Cohere Embed v3](https://cohere.com/embed)** - Advanced embedding models with improved accuracy
- **[OpenAI text-embedding-3](https://platform.openai.com/docs/guides/embeddings)** - Latest embedding models from OpenAI
- **[Sentence Transformers](https://www.sbert.net/)** - State-of-the-art sentence embeddings
- **[Jina Embeddings v2](https://jina.ai/embeddings/)** - 8K context length embeddings

## Knowledge Graph

- [MindGraph](https://github.com/yoheinakajima/MindGraph) proof of concept prototype for generating and querying against an ever-expanding knowledge graph with ai
- [LighRAG](https://github.com/HKUDS/LightRAG) LightRAG: Simple and Fast Retrieval-Augmented Generation". https://arxiv.org/abs/2410.05779

## Model Context Protocol (MCP) & AI Integration

### What is Model Context Protocol?
The Model Context Protocol (MCP) is an emerging standard that enables AI applications to securely connect to data sources and tools. It provides a unified way for AI systems to interact with external resources while maintaining security and consistency.

### MCP Tools & Servers
- **[MCP Tools](https://github.com/f/mcptools)** - Swiss Army Knife for MCP Servers. A comprehensive CLI for interacting with Model Context Protocol servers
- **[Active Pieces](https://github.com/activepieces/activepieces)** - AI Agents & MCPs & AI Workflow Automation with 280+ MCP servers
- **[MCP Agent](https://github.com/lastmile-ai/mcp-agent)** - Build effective agents using Model Context Protocol

### Popular MCP Servers
- **File System Server** - Access local files and directories
- **Database Server** - Connect to SQL databases
- **Git Server** - Interact with Git repositories
- **Web Search Server** - Perform web searches
- **Calendar Server** - Access calendar data
- **Slack Server** - Integrate with Slack workspaces

### MCP Benefits
- **Standardized Integration** - Consistent way to connect AI to external data
- **Security First** - Built-in permission and access controls
- **Tool Reusability** - Write once, use across multiple AI applications
- **Ecosystem Growth** - Growing library of pre-built servers

## Voice & Speech Technologies - 2025 Edition

### Revolutionary Speech AI Models - Kyutai Labs

**[Moshi](https://github.com/kyutai-labs/moshi)** - Real-time full-duplex speech-text foundation model
- **Latency**: 160ms theoretical (200ms practical on L4 GPU)
- **Architecture**: 7B parameter temporal transformer + depth transformer
- **Capabilities**: Bidirectional conversation with inner monologue
- **Platforms**: PyTorch, MLX (Apple Silicon), Rust, Swift
- **Live Demo**: [moshi.chat](https://moshi.chat)

**[Delayed Streams Modeling](https://github.com/kyutai-labs/delayed-streams-modeling)** - Advanced streaming STT
- **kyutai/stt-2.6b-en**: English-only, 2.6B params, 2.5s delay
- **kyutai/stt-1b-en_fr**: English/French, 1B params, 0.5s delay + semantic VAD
- **Performance**: Real-time streaming with word-level timestamps
- **Scale**: Production servers handle 64 simultaneous connections at 3x real-time

**[Unmute](https://unmute.sh/)** - Production speech processing platform
- Real-time speech enhancement and processing
- Production deployment of Kyutai models
- Live demo available for testing

### Mimi Neural Audio Codec

**Technical Specifications:**
- **Input**: 24 kHz audio
- **Output**: 12.5 Hz representation
- **Bandwidth**: 1.1 kbps with 80ms latency
- **Architecture**: Transformer-enhanced encoder/decoder
- **Performance**: Outperforms SpeechTokenizer and SemantiCodec

**Key Features:**
- Fully causal and streaming
- Matches WavLM representations without delays
- Adversarial training with feature matching
- Multiple implementation backends

### Implementation Options

**PyTorch (Research & Experimentation):**
```bash
python -m moshi.run_inference --hf-repo kyutai/stt-2.6b-en audio.mp3
```

**Rust (Production Deployment):**
```bash
cargo install --features cuda moshi-server
moshi-server worker --config config-stt-en-hf.toml
```

**MLX (Apple Silicon):**
```bash
python -m moshi_mlx.run_inference --hf-repo kyutai/stt-2.6b-en-mlx audio.mp3
```

**Real-time Features:**
- Streaming inference with chunked audio processing
- Easy batching (H100: 400 streams real-time)
- Word-level timestamps with semantic VAD
- Voice activity detection for natural conversations
